---
date: "2020-09-01"
featureImage: images/allpost/homework3.png
postImage: images/single-blog/0.jpg
title: Draft - Homework 3
---


```{r, setup, echo=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, echo=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(GGally)
library(readxl)
library(here)
library(skimr)
library(janitor)
library(broom)
library(tidyquant)
library(infer)
library(openintro)
library(kableExtra)
```


# Youth Risk Behavior Surveillance

Every two years, the Centers for Disease Control and Prevention conduct the [Youth Risk Behavior Surveillance System (YRBSS)](https://www.cdc.gov/healthyyouth/data/yrbs/index.htm) survey, where it takes data from high schoolers (9th through 12th grade), to analyze health patterns.  
We will work with a selected group of variables from a random sample of observations during one of the years the YRBSS was conducted.

## Load the data

This data is part of the `openintro` textbook and we can directly load and inspect it:

```{r}
data(yrbss)
glimpse(yrbss)
```

We have observations on 13 different variables, namely 

- the `age` in years
- `gender` female / male
- school`grade` 9-12
- `hispanic` or not
- `race` White / Asian / American Indian or Alaska Native / Black or African American / Native Hawaiian or Other Pacific Islander
- `height` in meters
- `weight` in kilograms
- `helmet_12m`: how often did you wear a helmet when biking in the last 12 months? did not ride / never / rarely / sometimes / most of time / always
- `text_while_driving_30d`: how many days did you text while driving in the last 30 days?
- `physically_active_7d`: how many days were you physically active for 60+ minutes in the last 7 days?
- `hours_tv_per_school_day`: how many hours of TV do you typically watch on a school night?
- `strength_training_7d`: how many days did you do strength training (e.g. lift weights) in the last 7 days?
- `school_night_hours_sleep` how many hours of sleep do you typically get on a school night?

Let's dive some deeper using `skim`:

```{r}
skim(yrbss)
```

We see that we have to deal with some missing data. Regarding our numerical variables, the values (min, max, histogram) seem very reasonable, even though some high schoolers seem to be quite small / tall and light / heavy. 

## Exploratory Data Analysis

As mentioned above, the range of `weight`s is quite big. Hence, let's have a closer look at this variable.
First, we can see from the `skim` output that there are 1004 observations with missing weights. 

Let's calculate summary statistics and visualize the distribution:

```{r eda_on_weight_1}

# calculate weight summary statistics
yrbss_weight_summary <- yrbss %>% 
  filter(!is.na(weight)) %>% # filter out NAs
  summarise(min = min(weight), 
            Q1 = quantile(weight, 0.25), 
            median = median(weight), 
            Q3= quantile(weight, 0.75), 
            max = max(weight),
            mean = mean(weight),
            sd = sd(weight))

# print summary statistics
yrbss_weight_summary %>% 
  kbl(caption = "summary statistics of the weight variable") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table

```


```{r eda_on_weight_2}

ggplot(yrbss, aes(x = weight)) +
  geom_histogram(binwidth = 2) + # binwidth = 2kg
  # add vertical lines for the mean and the median
  geom_vline(aes(xintercept = yrbss_weight_summary$median, colour = 'median'), linetype = 2, size = 1) +
  geom_vline(aes(xintercept = yrbss_weight_summary$mean, colour = 'mean'), linetype = 2, size = 1) +
  # change color of vertical lines
  scale_color_manual(name = NULL, values = c(median = "red", mean = "blue")) +
  # show median in legend before mean
  guides(color = guide_legend(reverse = TRUE)) +
  labs(title = "Distribution of weights") +
  theme_bw()
  
  
```

We can see that the distribution is a little bit right-skewed with quite some outliers of high weights.
However, the IQR seems not too big and around 50% of the pupils have a weight between 56 and 76, which seems reasonable.
Let's further visualise these findings with the help of a boxplot:



```{r eda_on_weight_3}

ggplot(yrbss, aes(x = weight)) +
  geom_boxplot() +
  theme_bw() +
  theme(axis.text.y = element_blank(),
        axis.ticks = element_blank())


```

Our analysis so far showed that most of the pupils seem to have normal weight. However, there are also quite some high schoolers
with too much weight. One explanation for this could be too little physical activity.  
Hence, let's have a look at the relationship between a high schoolerâ€™s weight and their physical activity:


```{r scatterplot_weight_physical}

# create plot 1
yrbss %>% 
  # only use observations with data for physically_active_7d and weight
  drop_na(physically_active_7d, weight) %>% 
  ggplot(aes(x = factor(physically_active_7d), y = weight)) +
  geom_boxplot() + # boxplot of weight per physically_active_7d
  labs(title = "no clear relationship betweeen weight and physical activeness",
       subtitle = "boxplots of weight per physical activeness",
       x = "days of 60+ minutes physical activeness in the last 7 days",
       y = "weight") +
  theme_bw()

# create plot 2
yrbss %>% 
  # only use observations with data for physically_active_7d and weight
  drop_na(physically_active_7d, weight) %>% 
  ggplot(aes(x = weight, y = stat(density))) + # show density and not counts for better comparison
  geom_freqpoly(aes(color = factor(physically_active_7d))) + # visualise distribution of weight per physically_active_7d
  labs(title = "no clear relationship between weight and physical activeness",
       subtitle = "distribution of weights by physical activeness",
       color = "days of 60+ \nminutes physical \nactiveness in the \nlast 7 days") +
  theme_bw()
  
    


```

There is no trend showing that higher physical activeness leads to less weight. The distributions of `weight` are almost the same for the different levels of physical activeness and it even looks like that there is a slight trend of higher physical activeness correlating with higher weight. 

However, let's dig deeper and see what we can find! We create a new variable `physical_3plus`, which will be `yes` if they are physically active for at least 3 days a week, and `no` otherwise.

  
```{r}
yrbss <- yrbss %>% 
  # create new variable `physical_3plus`
  mutate(physical_3plus = ifelse(physically_active_7d >= 3, "yes", "no"))

yrbss %>% 
  # only use observations with data for physical_3plus
  filter(!is.na(physical_3plus)) %>% 
  # group by "yes" / "no"
  group_by(physical_3plus) %>% 
  # count occurence
  summarise(count = n()) %>% 
  # calculate proportion
  mutate(prop= count/sum(count)) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table
  

```

We can see that approx. two third of the high schoolers are 3 or more times per week physically active for 60+ minutes!

Let's create a 95% confidence interval for the population proportion of high schoolers that are *not* active 3 or more days per week:


```{r CI_physical_3plus}

yrbss %>% 
  # only use observations with data for physical_3plus
  filter(!is.na(physical_3plus)) %>% 
  # calculate proportion for "no" physical_3plus
  summarise(n_yes = count(physical_3plus == "yes"),
            n_no = count(physical_3plus == "no"),
            count = n(),
            proportion = n_no / (n_yes + n_no)) %>% 
  # calculate CI
  mutate(sd = sqrt(proportion*(1-proportion)/count), 
         z_critical = qnorm(0.975), 
         `lower bound` = proportion - z_critical * sd, 
         `upper bound` = proportion + z_critical * sd) %>% 
  select(`lower bound`, proportion, `upper bound`) %>% 
  kbl(caption = "confidence interval for high schoolers that are not active 3 or more days per week") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table

```

Finally, we want to see if our newly created variable `physical_3plus` has a clearer relationship to `weight`:

```{r boxplot_physical_3plus}

yrbss %>% 
  # only use observations with data for physical_3plus and weight
  drop_na(physical_3plus, weight) %>% 
  ggplot(aes(x = physical_3plus, y = weight)) +
  geom_boxplot() + # boxplot of weight per physical_3plus
  labs(title = "Does physical activeness lead to higher weight?!",
       subtitle = "boxplots of weight per physical activeness",
       x = "were active for 60+ minutes on 3 days in the last 7 days",
       y = "weight") +
  theme_bw()

```

Just like before with the variable `physically_active_7d`, there is no clear relationship between physical activeness and weight.  
Opposed to our theory of higher physical activeness leading to lower weight, it even looks like there is a trend of higher physical activeness correlating with higher weight. This could be explained by older pupils with higher weight being more physically active. However, a deeper analysis is needed here!


## Confidence Interval

Boxplots show how the medians of the two distributions compare, but we can also compare the means of the distributions using either a confidence interval or a hypothesis test. 


```{r}

yrbss %>%
  group_by(physical_3plus) %>%
  # also filter out weight NAs!! Otherwise, count is too high and CI narrower than it actually is
  filter(!is.na(physical_3plus), !is.na(weight)) %>% 
  summarise(mean_weight = mean(weight),
            sd_weight = sd(weight),
            count = n(),
            se_weight = sd_weight/sqrt(count),
            t_critical = qt(0.975, count-1), 
            margin_of_error = t_critical * se_weight,
            lower = mean_weight - t_critical * se_weight,
            upper = mean_weight + t_critical * se_weight
            ) %>% 
  kbl(caption = "confidence interval for average weight by physical activeness (physical_3plus)") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table


```

There is an observed difference of about 1.77kg (68.44 - 66.67), and we notice that the two confidence intervals do not overlap. It seems that the difference is at least 95% statistically significant. Let us also conduct a hypothesis test.

## Hypothesis test with formula

First, we conduct a traditional t-test for the following hypotheses:

H0: mu_1 = mu_2, i.e. mean weights are *not* different for those who exercise at least 3 times a week vs those who don't  
H1: mu_1 != mu_2, i.e. mean weights *are* different for those who exercise at least 3 times a week vs those who don't 


```{r}
t.test(weight ~ physical_3plus, data = yrbss)
```

We can see that we have a very small p value, meaning that the data strongly implies that there is a difference in means. 


## Hypothesis test with `infer`


Next, we want to conduct the same hypothesis tests using simulation and the `infer` package.

Let us initialize this simulation based test and save it as `obs_diff`:

```{r}
obs_diff <- yrbss %>%
  specify(weight ~ physical_3plus) %>%
  calculate(stat = "diff in means", order = c("yes", "no")) # order yes - no

```


As a second step, we simulate the test on the null distribution, which we simulate using `generate`:


```{r}

# set random seed
set.seed(1234)

null_dist <- yrbss %>%
  specify(weight ~ physical_3plus) %>%
  # set null hypothesis (no difference between the two population means)
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>% # permute for hypothesis testing
  calculate(stat = "diff in means", order = c("yes", "no"))

```

We can visualize this null distribution with the following code:

```{r}
ggplot(data = null_dist, aes(x = stat)) +
  geom_histogram() +
  theme_bw()

```


Now that the test is initialized and the null distribution formed, we can visualise to see how many of these null permutations have a difference of at least `r obs_diff %>% pull() %>% round(2)`.

We can also calculate the p-value for the hypothesis test.

```{r}

null_dist %>% visualize() +
  shade_p_value(obs_stat = obs_diff, direction = "two-sided") + 
  theme_bw()

null_dist %>%
  get_p_value(obs_stat = obs_diff, direction = "two_sided") %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table
  

```

This is the standard workflow for performing hypothesis tests. Again, we see that the data strongly implies that there is a difference in means.

# IMDB ratings: Differences between directors

Recall the IMBD ratings data. We want to produce a new blockbuster and have the option to either work
with Steven Spielberg or Tim Burton. As our goal is a top-rated movie, we want to find out whether the mean IMDB rating for
Steven Spielberg and Tim Burton are the same or not.

Looking merely at the confidence intervals for the means is not really helpful in decision making, as they overlap:

```{r CI_spielberg_burton, fig.width = 8.8, fig.height=5.48}

# load data
movies <- read_csv(here::here("project_data", "movies.csv"))

# calculate CIs
formula_CI_movies <- movies %>% 
  # group data by director and filter for Burton and Spielberg
  group_by(director) %>% 
  filter(director %in% c("Tim Burton", "Steven Spielberg")) %>% 
  # calculate CIs
  summarise(average_rating = mean(rating), # calculate average rating
            SD_rating = sd(rating), # calculate standard deviation
            count = n(), # get the number of observations
            t_critical = qt(0.975, count - 1), # get t-critical value with (count-1) degrees of freedom
            SE =  SD_rating/sqrt(count), # calculate standard error
            margin_of_error = t_critical * SE, # calculate margin of error
            lower_ci = average_rating - margin_of_error, # calculate lower bound of the CI
            upper_ci = average_rating + margin_of_error) # calculate upper bound of the CI

# needed for gray overlapping area
xmin_rect = formula_CI_movies %>% 
  filter(director == "Steven Spielberg") %>% 
  select(lower_ci)

# needed for gray overlapping area
xmax_rect = formula_CI_movies %>% 
  filter(director == "Tim Burton") %>% 
  select(upper_ci)

# plot CIs
ggplot(formula_CI_movies, aes(y=factor(director, levels = c("Tim Burton", "Steven Spielberg")), 
                              x = average_rating, group = director)) +
  #draw the means
  geom_point(aes(color=director), size = 5) +
  #draws the CI error bars
  geom_errorbar(aes(xmin=lower_ci, xmax=upper_ci, color=director), width=.1, size = 2) +
  # add the lower_ci labels
  geom_text(aes(label = round(lower_ci,2), x = lower_ci),
            hjust = 0.3, # adjust position horizontally
            vjust = -1, # adjust position vertically
            size = 5) + # size of text
  # add the upper_ci labels
  geom_text(aes(label = round(upper_ci,2), x = upper_ci), 
            hjust = 0.3, # adjust position horizontally
            vjust = -1, # adjust position vertically
            size = 5) + # size of text
  # add the average labels
  geom_text(aes(label = round(average_rating,2), x = average_rating), 
            hjust = 0.4, # adjust position horizontally
            vjust = -0.8, # adjust position vertically
            size = 7) + # size of text
  # add gray overlap area
  geom_rect(aes(xmin = xmin_rect$lower_ci, xmax = xmax_rect$upper_ci, ymin = -Inf, ymax = Inf), alpha = 0.2) +
  theme_bw() +
  theme(legend.position = "none") +
  labs(title = "Do Spielberg and Burton have the same mean IMDB ratings?",
       subtitle = "95% confidence intervals overlap",
       y = "",
       x = "Mean IMDB Rating")

```

Original Plot:

```{r directors, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "directors.png"), error = FALSE)
```


Hence, let's conduct a hypothesis test. We will both use a traditional t-test and a simulation based test with the `infer` package.

Our hypotheses are:

H0: mu_1 = mu_2, i.e. mean ratings are *not* different for Steven Spielberg and Tim Burton  
H1: mu_1 != mu_2, i.e. mean ratings *are* different for Steven Spielberg and Tim Burton 

Conducting a traditional t-test yields:


```{r t_test_Spielberg_Burton}

rating_test <- movies %>% 
  # only take relevant information
  filter(director %in% c("Tim Burton", "Steven Spielberg")) %>% 
  select(director, rating)
  
t.test(rating ~ director, data = rating_test)

```

As a result of the traditional test, we get a test statistic with t = 3 and a p-value of 0.01. This means that under the assumption of no difference in rating means (i.e. H0), there is only a probability of 1% that we would have sampled our movies dataset or a more extreme set (with an even higher difference in rating means).
Hence, our data strongly implies that there is a difference in rating means! Assuming a alpha level of 5% (t has to be >= 2), we thus reject H0.

Let's now see what the result of a simulation based test is:

```{r simulation_Spielberg_Burton}

# calculate actual diff in means
obs_diff <- rating_test %>%
  specify(rating ~ director) %>%
  calculate(stat = "diff in means", order = c("Steven Spielberg", "Tim Burton")) # order Spielberg - Burton

# simulate null distribution
null_dist <- rating_test %>%
  specify(rating ~ director) %>%
  # set null hypothesis (no difference between the two population means)
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>% # permute for hypothesis testing
  calculate(stat = "diff in means", order = c("Steven Spielberg", "Tim Burton"))

# visualise p_value and null distribution
null_dist %>% visualize() +
  shade_p_value(obs_stat = obs_diff, direction = "two-sided") +
  theme_bw()

# print out p value
null_dist %>%
  get_p_value(obs_stat = obs_diff, direction = "two_sided") %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table

```

The p-value for the simulation based test is roughly the same as the one for our traditional test. Hence, the same interpretation holds true. 


# Omega Group plc- Pay Discrimination


At the last board meeting of Omega Group Plc., the headquarters of a large multinational company, the issue was raised that women were being discriminated in the company, in the sense that the salaries were not the same for male and female executives. A quick analysis of a sample of 50 employees (of which 24 men and 26 women) revealed that the average salary for men was about 8,700 higher than for women. This seemed like a considerable difference, so it was decided that a further analysis of the company salaries was warranted. 

The objective is to find out whether there is indeed a significant difference between the salaries of men and women, and whether the difference is due to discrimination or whether it is based on another, possibly valid, determining factor. 

## Loading the data

First, let's load the data and have a look:

```{r load_omega_data}
omega <- read_csv(here::here("project_data", "omega.csv"))
glimpse(omega) # examine the data frame
skim(omega)
```

We notice that no values are missing and that the values for gender, salary and experience seem reasonable.


## Relationship Salary - Gender ?

The data frame `omega`  contains the salaries for the sample of 50 executives in the company. Let's find out if we can conclude that there is a significant difference between the salaries of the male and female executives.

First, let's have a look at summary statistics, boxplots and confidence intervals:

```{r CI_gender_salary}

# Summary Statistics of salary by gender
mosaic::favstats(salary ~ gender, data=omega) %>% 
  kbl(caption = "summary statistics on salary by gender") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table

# plot boxplots
omega %>% 
  ggplot(aes(x = gender, y = salary)) +
  geom_boxplot() + # boxplot of salary per male/female
  labs(title = "men earn more than women!",
       subtitle = "boxplots of salary per gender",
       x = "") +
  theme_bw()

# calculate CIs for gender male and female
CI_omega <- omega %>% 
  # group by gender and calculate mean, SD, sample size, t-critical value, SE and MoE
  group_by(gender) %>% 
  summarise(mean = mean(salary), # calculate average salary
            SD = sd(salary), # calculate standard deviation
            `sample size` = n(), # get the number of observations
            `t-critical value` = qt(0.975, `sample size` - 1), # get t-critical value with (`sample size`-1) degrees of freedom
            `standard error` =  SD/sqrt(`sample size`), # calculate standard error
            `margin of error` = `t-critical value` * `standard error`, # calculate margin of error
            `lower CI bound` = mean - `margin of error`, # calculate lower bound of the CI
            `upper CI bound` = mean + `margin of error`) # calculate upper bound of the CI

# print table with CIs
CI_omega %>% 
  kbl(caption = "95% confidence interval on average salary") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table
  

# plot CIs
ggplot(CI_omega, aes(y=gender, x = mean, group = gender, color=gender)) +
  #draws the means
  geom_point(size = 5) +
  #draws the CI error bars
  geom_errorbar(aes(xmin=`lower CI bound`, xmax=`upper CI bound`), width=.1, size = 2) +
  theme_bw() +
  theme(legend.position = "none") +
  labs(title = "95% confidence intervals on salary by gender do not overlap",
       y = "",
       x = "salary")


```

As the two confidence intervals do not overlap, it seems that the difference is at least 95% statistically significant. Let us also conduct a hypothesis test.

Our hypotheses are as follows:

H0: mu_1 = mu_2, i.e. mean salaries are *not* different for men and women  
H1: mu_1 != mu_2, i.e. mean salaries *are* different for men and women

Conducting a traditional t-test yields:

```{r t_test_gender_salary}

t.test(salary ~ gender, data = omega)

```

As a result of the traditional test, we get a test statistic with t = -4 and a p-value of close to zero. This means that under the assumption of no difference in salary means (i.e. H0), there is only a very very small probability that we would have sampled our omega dataset or a more extreme set (with an even higher difference in salary means).
Hence, our data strongly implies that there is a difference in salary means! Assuming a alpha level of 5% (t has to be <= -2), we thus reject H0.

Let's now see what the result of a simulation based test is:

```{r simulation_gender_salary}

# calculate actual diff in means
obs_diff <- omega %>%
  specify(salary ~ gender) %>%
  calculate(stat = "diff in means", order = c("male", "female")) # order male - female

# simulate null distribution
null_dist <- omega %>%
  specify(salary ~ gender) %>%
  # set null hypothesis (no difference between the two population means)
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>% # permute for hypothesis testing
  calculate(stat = "diff in means", order = c("male", "female"))

# visualise p_value and null distribution
null_dist %>% visualize() +
  shade_p_value(obs_stat = obs_diff, direction = "two-sided") +
  theme_bw()

# print out p value
null_dist %>%
  get_p_value(obs_stat = obs_diff, direction = "two_sided") %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table

```

The p-value for the simulation based test is basically the same as the one for our traditional test. Hence, the same interpretation holds true. 

All in all, we can be quite certain that there really is a difference in mean salary between men and women. However, this does not mean that there is a direct causality between those two variables. It is possible that for example most women have less experience than men in this dataset, which would explain the lower average salary. Hence, it is still possible that there is no "real" gender pay gap. However, at the moment it looks like the gender pay gap is reality!


## Relationship Experience - Gender?

We want to dig deeper on the concerns we have just raised and have a look at the relationship between experience and gender.  
Indeed, the average experience of the men is approximately 21 years, whereas the women only have about 7 years experience on average:

```{r experience_stats}

favstats (experience ~ gender, data=omega) %>% 
  kbl(caption = "summary statistics on experience by gender") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table

```

Let's also have a look at boxplots and confidence intervals:

```{r CI_gender_experience}

# plot boxplots
omega %>% 
  ggplot(aes(x = gender, y = experience)) +
  geom_boxplot() + # boxplot of experience per male/female
  labs(title = "men at omega have more experience than women!",
       subtitle = "boxplots of experience per gender",
       x = "") +
  theme_bw()

# calculate CIs for gender male and female
CI_omega <- omega %>% 
  # group by gender and calculate mean, SD, sample size, t-critical value, SE and MoE
  group_by(gender) %>% 
  summarise(mean = mean(experience), # calculate average
            SD = sd(experience), # calculate standard deviation
            `sample size` = n(), # get the number of observations
            `t-critical value` = qt(0.975, `sample size` - 1), # get t-critical value with (`sample size`-1) degrees of freedom
            `standard error` =  SD/sqrt(`sample size`), # calculate standard error
            `margin of error` = `t-critical value` * `standard error`, # calculate margin of error
            `lower CI bound` = mean - `margin of error`, # calculate lower bound of the CI
            `upper CI bound` = mean + `margin of error`) # calculate upper bound of the CI

# print table with CIs
CI_omega %>% 
  kbl(caption = "95% confidence intervals on average experience") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table
  

# plot CIs
ggplot(CI_omega, aes(y=gender, x = mean, group = gender, color=gender)) +
  #draws the means
  geom_point(size = 5) +
  #draws the CI error bars
  geom_errorbar(aes(xmin=`lower CI bound`, xmax=`upper CI bound`), width=.1, size = 2) +
  theme_bw() +
  theme(legend.position = "none") +
  labs(title = "95% confidence intervals on experience by gender do not overlap",
       y = "",
       x = "experience")


```

As the two confidence intervals do not overlap, it seems that the difference is at least 95% statistically significant. Let us also conduct a hypothesis test.

Our hypotheses are as follows:

H0: mu_1 = mu_2, i.e. mean experiences are *not* different for men and women  
H1: mu_1 != mu_2, i.e. mean experiences *are* different for men and women

Conducting a traditional t-test yields:

```{r t_test_gender_experience}

t.test(experience ~ gender, data = omega)

```

As a result of the traditional test, we get a test statistic with t = -5 and a p-value of close to zero. This means that under the assumption of no difference in experience means (i.e. H0), there is only a very very small probability that we would have sampled our omega dataset or a more extreme set (with an even higher difference in experience means).
Hence, our data strongly implies that there is a difference in experience means! Assuming a alpha level of 5% (t has to be <= -2), we thus reject H0.

Let's now see what the result of a simulation based test is:

```{r simulation_gender_experience}

# calculate actual diff in means
obs_diff <- omega %>%
  specify(experience ~ gender) %>%
  calculate(stat = "diff in means", order = c("male", "female")) # order male - female

# simulate null distribution
null_dist <- omega %>%
  specify(experience ~ gender) %>%
  # set null hypothesis (no difference between the two population means)
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>% # permute for hypothesis testing
  calculate(stat = "diff in means", order = c("male", "female"))

# visualise p_value and null distribution
null_dist %>% visualize() +
  shade_p_value(obs_stat = obs_diff, direction = "two-sided") +
  theme_bw()

# print out p value
null_dist %>%
  get_p_value(obs_stat = obs_diff, direction = "two_sided") %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table

```

The p-value for the simulation based test is basically the same as the one for our traditional test. Hence, the same interpretation holds true. 

All in all, we can be quite certain that there really is a difference in mean experience between men and women.  
This could definitely explain why women are paid less than men! 


## Relationship Salary - Experience ?

Due to our findings above, a more thorough analysis of the relationship between salary and experience is required before any conclusion can be drawn about whether there is any gender-based salary discrimination in the company.

Hence, have a look at the following graphs:


```{r salary_exp_scatter}

ggplot(omega, aes(x = experience, y = salary)) +
  geom_point(aes(color = gender)) +
  geom_smooth(method = lm, se = FALSE) +
  theme_bw() +
  labs(title = "higher experience means higher salary")

ggplot(omega, aes(x = experience, y = salary, color = gender)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  theme_bw() +
  labs(title = "higher experience means higher salary")

```

This reinforces our reasoning above: Higher experience leads to a higher salary. But as the women in our dataset have overally less experience than the men, this also means that they are paid less. However, this is probably mainly due to the difference in experience.


## Check correlations between the data

Finally, let's have a look at the following graph:


```{r ggpairs}
omega %>% 
  select(gender, experience, salary) %>% # order variables they will appear in ggpairs()
  ggpairs(aes(colour=gender, alpha = 0.3)) + # create scatterplot and correlation matrix, color by gender
  theme_bw()
```

Especially the salary vs experience scatterplot colored by gender is quite revealing: Looking only at experiences >0, we can clearly see that women are in general *not* paid less than men. The pattern between male / female is quite random, with sometimes men being paid better (given fixed experience) and sometimes women being paid better (given fixed experience). Hence, the gender pay gap seems to be disproved.  
However, there are quite some women with 0 experience. Those are also the ones that are paid least. As there are no men in our data with 0 experience, it is hard to tell if women with 0 experience are systematically discriminated. 


# Challenge 1: Brexit plot

Plot Reproduction:

```{r uk_challenge, fig.width=10, fig.height=6}

# load brexit data
brexit_results <- read_csv(here::here("project_data","brexit_results.csv"))

brexit_results %>% 
  # get party vote percentages into long format (one column with party names, another with the percentages)
  pivot_longer(cols = con_2015:ukip_2015, names_to = "party", values_to = "party_percent") %>% 
  # label the parties with readable names
  mutate(party = factor(party, labels = c("Conservative", "Labour", "Lib Dems", "UKIP"))) %>% 
  # ggplot framework, color by party
  ggplot(aes(x = party_percent, y = leave_share, color = party)) +
  # add scatterplot with opacity 0.3
  geom_point(alpha = 0.3) + 
  # add linear smoothing line for each party
  geom_smooth(method = lm) +
  # use party-specific colors
  scale_color_manual(values=c("#0087dc", "#d50000", "#FDBB30", "#EFE600")) + # change colors
  # bw theme
  theme_bw() +
  # labels
  labs(title = "How political affiliation translated to Brexit Voting",
       x = "Party % in the UK 2015 general election", 
       y = "Leave % in the 2016 Brexit referendum") +
  # have legend vertically on the bottom with no title
  theme(legend.position = "bottom",
        legend.box = "vertical",
        legend.title = element_blank())

```

Original Plot:

```{r brexit_challenge, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "brexit.png"), error = FALSE)
```

# Challenge 2:GDP components over time and among countries

At the risk of oversimplifying things, the main components of gross domestic product, GDP are personal consumption (C), business investment (I), government spending (G) and net exports (exports - imports). You can read more about GDP and the different approaches in calculating at the [Wikipedia GDP page](https://en.wikipedia.org/wiki/Gross_domestic_product).

The GDP data we will look at is from the [United Nations' National Accounts Main Aggregates Database](https://unstats.un.org/unsd/snaama/Downloads), which contains estimates of total GDP and its components for all countries from 1970 to today. We will look at how GDP and its components have changed over time, and compare different countries and how much each component contributes to that country's GDP. The file we will work with is [GDP and its breakdown at constant 2010 prices in US Dollars](http://unstats.un.org/unsd/amaapi/api/file/6).


```{r read_GDP_data}

UN_GDP_data  <- read_excel(here::here("project_data", "Download-GDPconstant-USD-countries.xls"), # Excel filename
                sheet="Download-GDPconstant-USD-countr", # Sheet name
                skip=2) # Number of rows to skip

```


We first tidy up the data, as it is in wide format. Furthermore, we divide by `1e9` to express all figures in billions and rename
the indicators into something shorter.


```{r reshape_GDP_data}

# for the values remapping / renaming
from = c("Household consumption expenditure (including Non-profit institutions serving households)",
         "General government final consumption expenditure",
         "Exports of goods and services",
         "Imports of goods and services")

to = c("Household expenditure",
       "Government expenditure",
       "Exports",
       "Imports")

tidy_GDP_data <- UN_GDP_data %>% 
  # bring into long format
  pivot_longer(cols = `1970`:`2017`, names_to = "year", values_to = "values") %>% 
  # express in billions
  mutate(values = values / 1e9) %>% 
  # rename indicators
  mutate(IndicatorName = plyr::mapvalues(IndicatorName, from, to))


# let's have a look at the data
glimpse(tidy_GDP_data)


# Let us compare GDP components for these 3 countries
country_list <- c("United States","India", "Germany")

```

Plot Reproduction:

```{r challenge_2_1, fig.width = 9, fig.height=5.5}

# create plot
tidy_GDP_data %>% 
  # only visualise for countries in the country_list
  filter(Country %in% country_list) %>% 
  # only visualise certain indicators
  filter(IndicatorName %in% c("Gross capital formation", 
                              "Exports", 
                              "Government expenditure", 
                              "Household expenditure", 
                              "Imports")) %>% 
  # make indicator a factor with correct ordering
  mutate(IndicatorName = factor(IndicatorName, 
                                levels = c("Gross capital formation",
                                           "Exports",
                                           "Government expenditure",
                                           "Household expenditure",
                                           "Imports"))) %>% 
  # ggplot framework
  ggplot(aes(x = year, y = values, color = IndicatorName)) +
  # add lines
  geom_line(aes(group = IndicatorName), size = 0.8) + 
  # faceting by country
  facet_wrap(~Country) +
  # custom scale breaks
  scale_x_discrete(breaks = c(1970, 1980, 1990, 2000, 2010)) +
  # bw theme
  theme_bw() +
  # labels (also for the legend)
  labs(title = "GDP components over time",
       subtitle = "In constant 2010 USD",
       x = "",
       y = "Billion US$",
       color = "Components of GDP")
  

```


original Plot:


```{r gdp1, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "gdp1.png"), error = FALSE)
```


Secondly, recall that GDP is the sum of Household Expenditure (Consumption *C*), Gross Capital Formation (business investment *I*), Government Expenditure (G) and Net Exports (exports - imports). Even though there is an indicator `Gross Domestic Product (GDP)` in the dataframe, we calculate it given its components discussed above.

```{r GDP_calculation}

# wrangle data and calculate GDP
tidy_GDP_data_2 <- tidy_GDP_data %>% 
  # bring in wide format to easily calculate GDP
  pivot_wider(names_from = IndicatorName, values_from = values) %>% 
  # calculate Net Exports, GDP and % difference in GDPs
  mutate(`Net Exports` = Exports-Imports,
         `Calculated GDP` = `Household expenditure` + `Gross capital formation` + `Government expenditure` + `Net Exports`,
         `Percentage Change` = (`Calculated GDP` - `Gross Domestic Product (GDP)`)/`Gross Domestic Product (GDP)`)

# summary statistics
mosaic::favstats(~`Percentage Change`, data=tidy_GDP_data_2) %>% 
  kbl(caption = "overall summary statistics for the % difference between calculated and included GDP") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table

# summary statistics
#mosaic::favstats(`Percentage Change`~year, data=tidy_GDP_data_2) %>% 
#  kbl(caption = "summary statistics for the % difference between calculated and included GDP per year") %>%
#  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) # have a nice HTML table

```

As we can see, the % difference of the two GDPs is in most cases around 0, i.e. both GDPs are in most cases approximately the same.

Plot Reproduction:

```{r challenge_2_2, fig.width = 12, fig.height=6}

# prepare data and plot
tidy_GDP_data_2 %>% 
  # calculate the percentage values
  mutate(`Government Expenditure` = `Government expenditure` / `Gross Domestic Product (GDP)`,
         `Gross capital formation` = `Gross capital formation` / `Gross Domestic Product (GDP)`,
         `Household Expenditure` = `Household expenditure` / `Gross Domestic Product (GDP)`,
         `Net Exports` = `Net Exports` / `Gross Domestic Product (GDP)`) %>% 
  # bring back into long format
  pivot_longer(cols = `Final consumption expenditure`:`Household Expenditure`, 
               names_to = "IndicatorName", 
               values_to = "values") %>% 
  # only visualise for countries in the country_list
  filter(Country %in% country_list) %>% 
  # only visualise certain indicators
  filter(IndicatorName %in% c("Gross capital formation", 
                              "Government Expenditure", 
                              "Household Expenditure", 
                              "Net Exports")) %>% 
  # ggplot framework
  ggplot(aes(x = year, y = values, color = IndicatorName)) +
  # add lines
  geom_line(aes(group = IndicatorName), size = 0.8) + 
  # faceting by country
  facet_wrap(~Country) +
  # custom scale breaks
  scale_x_discrete(breaks = c(1970, 1980, 1990, 2000, 2010)) +
  # percentage scale on y axis
  scale_y_continuous(labels = scales::percent) +
  # bw theme
  theme_bw() +
  # labels
  labs(title = "GDP and its breakdown at constant 2010 prices in US Dollars",
       caption = "Source: United Nations, https://unstats.un.org/unsd/snaama/Downloads",
       x = "",
       y = "proportion") +
  # no legend title
  theme(legend.title = element_blank())

```

Original Plot:

```{r gdp2, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "gdp2.png"), error = FALSE)
```


First, let's have a look at the net export proportion. In India and the United States, there is a trend towards higher imports as opposed to lower exports. For Germany, we can see the opposite effect, meaning that its net exports are growing at a higher rate than its overall GDP.
Regarding the proportion of gross capital formation, i.e. investments, we can see that there is a sharp rise in India in the 2000s. In the US, the proportion of GCF is also slightly rising, whereas the proportion in Germany dropped.  
The proportion of Government expenditure is quite steady in India and Germany, whereas it dropped in the US.  
Finally, household expenditure dropped significantly in India (with the investments going up), wheres they are steady in Germany and rising in the US. 

All in all, we can conclude the following: 

- Proportions in Germany are quite steady, with its net exports rate rising
- In India, businesses are more and more investing, while the household expenditure rate drops
- While government expenditure rates drop, households and businesses (have to) invest more in the US. This can be well explained by the rise of neo-liberalism and a lower influence of the public sector

# Details

- Who did you collaborate with: Noor Alameri, Brigita Angkasa, Lujia Huang, Martino Armanini, Marco Laube, Deniz Oezdemir
- Approximately how much time did you spend on this problem set: 10h
- What, if anything, gave you the most trouble: Details, Details, Details

# Rubric

Check minus (1/5): Displays minimal effort. Doesn't complete all components. Code is poorly written and not documented. Uses the same type of plot for each graph, or doesn't use plots appropriate for the variables being analyzed. 

Check (3/5): Solid effort. Hits all the elements. No clear mistakes. Easy to follow (both the code and the output). 

Check plus (5/5): Finished all components of the assignment correctly and addressed both challenges. Code is well-documented (both self-documented and with additional comments as necessary). Used tidyverse, instead of base R. Graphs and tables are properly labelled. Analysis is clear and easy to follow, either because graphs are labeled clearly or you've written additional text to describe how you interpret the output.



