---
date: "2020-09-01"
featureImage: images/allpost/homework2.png
postImage: images/single-blog/0.jpg
title: Draft - Homework 2
---

<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>
<link href="/rmarkdown-libs/lightable/lightable.css" rel="stylesheet" />


<div id="climate-change-and-temperature-anomalies" class="section level1">
<h1>Climate change and temperature anomalies</h1>
<p>We want to study climate change and gratefully find data on the <em>Combined Land-Surface Air and Sea-Surface Water Temperature Anomalies</em> in the Northern Hemisphere at <a href="https://data.giss.nasa.gov/gistemp">NASA’s Goddard Institute for Space Studies</a>. The <a href="https://data.giss.nasa.gov/gistemp/tabledata_v3/NH.Ts+dSST.txt">tabular data of temperature anomalies can be found here</a>.</p>
<p>To define temperature anomalies, we need to have a reference, or base period, which NASA clearly states that it is the period between 1951-1980.</p>
<p>Let’s load the data and have a look!</p>
<pre class="r"><code>weather &lt;- 
  read_csv(&quot;https://data.giss.nasa.gov/gistemp/tabledata_v3/NH.Ts+dSST.csv&quot;, 
           skip = 1, # start in row 2
           na = &quot;***&quot;) # recognize *** as NAs</code></pre>
<p>For each month and year, the dataframe shows the deviation of temperature from the normal (expected). Furthermore, the dataframe is in wide format. Hence, we first bring it into long format, which makes it easier to analyse the data:</p>
<pre class="r"><code># bring data in tidy format
tidyweather &lt;- weather %&gt;%
  # only use year and month columns
  select(Year:Dec) %&gt;%
  # bring into long format
  pivot_longer(cols = Jan:Dec, names_to = &quot;Month&quot;, values_to = &quot;delta&quot;) 

# print 10 rows of the table to have a look at the transformed data
tidyweather %&gt;% 
  head(10) %&gt;% 
  kbl   () %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;))</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
Year
</th>
<th style="text-align:left;">
Month
</th>
<th style="text-align:right;">
delta
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1880
</td>
<td style="text-align:left;">
Jan
</td>
<td style="text-align:right;">
-0.54
</td>
</tr>
<tr>
<td style="text-align:right;">
1880
</td>
<td style="text-align:left;">
Feb
</td>
<td style="text-align:right;">
-0.38
</td>
</tr>
<tr>
<td style="text-align:right;">
1880
</td>
<td style="text-align:left;">
Mar
</td>
<td style="text-align:right;">
-0.26
</td>
</tr>
<tr>
<td style="text-align:right;">
1880
</td>
<td style="text-align:left;">
Apr
</td>
<td style="text-align:right;">
-0.37
</td>
</tr>
<tr>
<td style="text-align:right;">
1880
</td>
<td style="text-align:left;">
May
</td>
<td style="text-align:right;">
-0.11
</td>
</tr>
<tr>
<td style="text-align:right;">
1880
</td>
<td style="text-align:left;">
Jun
</td>
<td style="text-align:right;">
-0.22
</td>
</tr>
<tr>
<td style="text-align:right;">
1880
</td>
<td style="text-align:left;">
Jul
</td>
<td style="text-align:right;">
-0.23
</td>
</tr>
<tr>
<td style="text-align:right;">
1880
</td>
<td style="text-align:left;">
Aug
</td>
<td style="text-align:right;">
-0.24
</td>
</tr>
<tr>
<td style="text-align:right;">
1880
</td>
<td style="text-align:left;">
Sep
</td>
<td style="text-align:right;">
-0.26
</td>
</tr>
<tr>
<td style="text-align:right;">
1880
</td>
<td style="text-align:left;">
Oct
</td>
<td style="text-align:right;">
-0.32
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>glimpse(tidyweather)</code></pre>
<pre><code>## Rows: 1,680
## Columns: 3
## $ Year  &lt;dbl&gt; 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1...
## $ Month &lt;chr&gt; &quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;...
## $ delta &lt;dbl&gt; -0.54, -0.38, -0.26, -0.37, -0.11, -0.22, -0.23, -0.24, -0.26...</code></pre>
<p>Note that <code>Year</code> and <code>Month</code> are stored as <code>double</code> and <code>character</code> variables (and not as <code>date</code> variables).</p>
<div id="plotting-information" class="section level2">
<h2>Plotting Information</h2>
<p>To be able to create a nice time series plot, we first need to create a new variable called <code>date</code>, in order to ensure that the <code>delta</code> values are plot chronologically.</p>
<pre class="r"><code>tidyweather &lt;- tidyweather %&gt;%
  mutate(date = ymd(paste(as.character(Year), Month, &quot;1&quot;)), # create `date` variable with lubridate
         month = month(date, label=TRUE),
         year = year(date))

# plot a timeseries scatterplot of all the deltas
ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point() +
  geom_smooth(color=&quot;red&quot;) + # add smoothed red line
  theme_bw() +
  labs (
    title = &quot;Increasing Weather Anomalies Demonstrating Global Warming&quot;,
    caption = &quot;Source: NASA&quot;
  )</code></pre>
<p><img src="/blog/homework2_files/figure-html/scatter_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>As we can clearly see, there seems to be a strong trend towards warm weather anomalies!</p>
<p>Is the effect of increasing temperature more pronounced in some months? Let’s have a look:</p>
<p><img src="/blog/homework2_files/figure-html/facet_wrap-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>We can see that the effect is almost the same for every month!</p>
<p>As a next step for our analysis of global warming, we group the years into bigger periods:</p>
<pre class="r"><code>comparison &lt;- tidyweather %&gt;% 
  filter(Year&gt;= 1881) %&gt;%     #remove years prior to 1881
  #create new variable &#39;interval&#39;, and assign values based on criteria below:
  mutate(interval = case_when(
    Year %in% c(1881:1920) ~ &quot;1881-1920&quot;,
    Year %in% c(1921:1950) ~ &quot;1921-1950&quot;,
    Year %in% c(1951:1980) ~ &quot;1951-1980&quot;,
    Year %in% c(1981:2010) ~ &quot;1981-2010&quot;,
    TRUE ~ &quot;2011-present&quot;
  ))</code></pre>
<p>Using our new <code>interval</code> variable, we are able to create a density plot to study the distribution of monthly deviations, grouped by the different time periods.</p>
<pre class="r"><code>ggplot(comparison, aes(x=delta, fill=interval))+
  geom_density(alpha=0.2) +   # density plot with transparency set to 20%
  theme_bw() +                # theme
  labs (
    title = &quot;The Bells are Moving!&quot;,
    subtitle = &quot;Density Plot for Monthly Temperature Anomalies&quot;,
    y     = &quot;Density&quot;,         # changing y-axis label to sentence case
    caption = &quot;Source: NASA&quot;
  )</code></pre>
<p><img src="/blog/homework2_files/figure-html/density_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Again, we can clearly recognize the pattern of global warming!</p>
<p>So far, we have been working with monthly anomalies. However, we are also interested in average annual anomalies.</p>
<p>Let’s have a look, how they look like:</p>
<pre class="r"><code>#creating yearly averages
average_annual_anomaly &lt;- tidyweather %&gt;% 
  group_by(year) %&gt;%   #grouping data by Year
  
  # creating summaries for mean delta 
  # use `na.rm=TRUE` to eliminate NA (not available) values 
  summarise(annual_average_delta = mean(delta, na.rm=TRUE)) 

#plotting the data:
ggplot(average_annual_anomaly, aes(x=year, y= annual_average_delta))+
  geom_point()+
  #Fit the best fit line, using LOESS method
  geom_smooth(method = &quot;loess&quot;) +
  #change to theme_bw() to have white background + black frame around plot
  theme_bw() +
  labs (
    title = &quot;Global Warming is REAL!!&quot;,
    subtitle = &quot;Average Yearly Anomaly&quot;,
    y     = &quot;Average Annual Delta&quot;,
    caption = &quot;Source: NASA&quot;
  )                         </code></pre>
<p><img src="/blog/homework2_files/figure-html/averaging-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Once more, the message is pretty clear: global warming is real!</p>
</div>
<div id="confidence-interval-for-delta" class="section level2">
<h2>Confidence Interval for <code>delta</code></h2>
<p><a href="https://earthobservatory.nasa.gov/world-of-change/decadaltemp.php">NASA points out on their website</a> that</p>
<blockquote>
<p>A one-degree global change is significant because it takes a vast amount of heat to warm all the oceans, atmosphere, and land by that much. In the past, a one- to two-degree drop was all it took to plunge the Earth into the Little Ice Age.</p>
</blockquote>
<p>So, do we already deal with a one-degree global change? For this purpose, we calculate a confidence interval for the time between 2011-present.</p>
<p>First, we want to do this using traditional formulas:</p>
<pre class="r"><code>formula_ci &lt;- comparison %&gt;% 
  # choose the interval 2011-present
  filter(interval == &quot;2011-present&quot;, !is.na(delta)) %&gt;%
  # calculate summary statistics for temperature deviation (delta) 
  # calculate mean, SD, count, SE, margin of error and lower/upper 95% CI
  summarise(mean_delta = mean(delta),
            sd_delta = sd(delta),
            count = n(),
            # get t-critical value with (n-1) degrees of freedom
            t_critical = qt(0.975, count-1),
            se_delta = sd_delta/sqrt(count),
            margin_of_error = t_critical * se_delta,
            delta_low = mean_delta - margin_of_error,
            delta_high = mean_delta + margin_of_error
  ) 

#print out formula_CI
formula_ci %&gt;% 
  select(delta_low, mean_delta, delta_high) %&gt;% # only show relevant columns
  rename(`lower bound` = delta_low, `mean delta` = mean_delta, `upper bound` = delta_high) %&gt;% # create readable names
  kbl(caption = &quot;confidence interval for mean delta since 2011 (formula)&quot;) %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) # have a nice HTML table</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<caption>
(#tab:calculate_CI_using_formula)confidence interval for mean delta since 2011 (formula)
</caption>
<thead>
<tr>
<th style="text-align:right;">
lower bound
</th>
<th style="text-align:right;">
mean delta
</th>
<th style="text-align:right;">
upper bound
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.915
</td>
<td style="text-align:right;">
0.966
</td>
<td style="text-align:right;">
1.02
</td>
</tr>
</tbody>
</table>
<p>Hence, we get an average delta of 0.966 and a confidence interval of [0.915, 1.02] under 97.5% confidence. As we can see, it seems not unlikely that there already is a one-degree global warming!</p>
<p>However, some people trust more into the simulation skills of their computers than into mathematical formulas. Hence, let’s calculate the confidence interval using bootstrapping!</p>
<pre class="r"><code># use the infer package to construct a 95% CI for delta

set.seed(1234)

boot_weather &lt;- comparison %&gt;%
  # Choose only 2011-present period
  filter(interval == &quot;2011-present&quot;, !is.na(delta)) %&gt;%
  # Specify the variable of interest
  specify(response = delta) %&gt;%
  # Generate a bunch of bootstrap samples
  generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;%
  # Find the mean of each sample
  calculate(stat = &quot;mean&quot;)

# calculate confidence interval
percentile_ci &lt;- boot_weather %&gt;%
  get_ci(level=0.95, type=&quot;percentile&quot;)

# print out confidence interval
percentile_ci %&gt;% 
  rename(`lower bound` = lower_ci, `upper bound` = upper_ci) %&gt;% # create readable names
  kbl(caption = &quot;confidence interval for mean delta since 2011 (simulated)&quot;) %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) # have a nice HTML table</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<caption>
(#tab:calculate_CI_using_bootstrap)confidence interval for mean delta since 2011 (simulated)
</caption>
<thead>
<tr>
<th style="text-align:right;">
lower bound
</th>
<th style="text-align:right;">
upper bound
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.917
</td>
<td style="text-align:right;">
1.02
</td>
</tr>
</tbody>
</table>
<pre class="r"><code># visualise both confidence intervals and the bootstrap distribution
ggplot(boot_weather, aes(x = stat)) +
  geom_histogram() +
  labs(title= &quot;Bootstrap distribution of means with confidence intervals&quot;) +
  # add confidence interval bounds as vertical lines
  geom_vline(aes(xintercept = percentile_ci$lower_ci, colour = &#39;bootstrap CI&#39;), linetype = 2, size = 1.1) +
  geom_vline(aes(xintercept = percentile_ci$upper_ci, colour = &#39;bootstrap CI&#39;), linetype = 2, size = 1.1) +
  geom_vline(aes(xintercept = formula_ci$delta_low, colour = &#39;formula CI&#39;), linetype = 1, size = 1.1) +
  geom_vline(aes(xintercept = formula_ci$delta_high, colour = &#39;formula CI&#39;), linetype = 1, size = 1.1) +
  # change color of the lines
  scale_color_manual(name = NULL, values = c(`bootstrap CI` = &quot;red&quot;, `formula CI` = &quot;orange&quot;)) +
  theme_bw()</code></pre>
<p><img src="/blog/homework2_files/figure-html/visualise_ci_bootstrap-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>We can see that the simulated CI and the mathematically calculated CI are very similar.</p>
<p>For the simulated CI, we resampled our sample 1000 times with replication (–&gt; bootstrapping).</p>
<p>For each of these 1000 “new” samples, we then calculated the average delta and obtained the bootstrap distribution as depicted above.</p>
<p>With the help of this simulated / approximated sample distribution (distribution of the mean delta), we were able to create our simulated CI by choosing upper and lower bounds, such that 95% of the (resampled) means are covered.</p>
</div>
</div>
<div id="general-social-survey-gss" class="section level1">
<h1>General Social Survey (GSS)</h1>
<p>The <a href="http://www.gss.norc.org/">General Social Survey (GSS)</a> gathers data on American society in order to monitor and explain trends in attitudes, behaviours, and attributes. Many trends have been tracked for decades, so one can see the evolution of attitudes, etc in American Society.</p>
<p>Let’s load this intersting data for the year 2016:</p>
<pre class="r"><code>gss &lt;- read_csv(here::here(&quot;project_data&quot;, &quot;smallgss2016.csv&quot;), 
                na = c(&quot;&quot;, &quot;Don&#39;t know&quot;,
                       &quot;No answer&quot;, &quot;Not applicable&quot;, &quot;NA&quot;))</code></pre>
<p>The variables we have in our data are the following:</p>
<ul>
<li>hours and minutes spent on email weekly. The responses to these questions are recorded in the <code>emailhr</code> and <code>emailmin</code> variables.</li>
<li><code>snapchat</code>, <code>instagrm</code>, <code>twitter</code>: whether respondents used these social media (in 2016)</li>
<li><code>sex</code>: Female or Male</li>
<li><code>degree</code>: highest education level attained</li>
</ul>
<div id="instagram-and-snapchat-by-sex" class="section level2">
<h2>Instagram and Snapchat, by sex</h2>
<p>We will now estimate the <em>population</em> proportion of Snapchat or Instagram users in 2016:</p>
<pre class="r"><code># calculate snap_insta, that measures Instagram and Snapchat use in combination
snap_insta_df &lt;- gss %&gt;%
  # &quot;Yes&quot; if the respondent reported using any of snapchat or instagrm, and &quot;No&quot; if not. If both NA then also NA.
  mutate(snap_insta = case_when(snapchat == &quot;Yes&quot; | instagrm == &quot;Yes&quot; ~ &quot;Yes&quot;,
                                is.na(snapchat) &amp; is.na(instagrm) ~ NA_character_ ,
                                TRUE ~ &quot;No&quot;)
         )

# print overall proportion
snap_insta_df %&gt;%
  summarise(`number of instagram/ snapchat users` = count(snap_insta == &quot;Yes&quot;),
            `number of people who use neither` = count(snap_insta == &quot;No&quot;),
            `proportion of instagram/ snapchat users` = count(snap_insta == &quot;Yes&quot;)/count(snap_insta %in% c(&quot;Yes&quot;,&quot;No&quot;))) %&gt;%
  kbl() %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) # have a nice HTML table</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
number of instagram/ snapchat users
</th>
<th style="text-align:right;">
number of people who use neither
</th>
<th style="text-align:right;">
proportion of instagram/ snapchat users
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
514
</td>
<td style="text-align:right;">
858
</td>
<td style="text-align:right;">
0.375
</td>
</tr>
</tbody>
</table>
<p>Hence, our best guess is that overall 37.5% of the whole population use instagram, snapchat, or both.</p>
<p>But it’s always better to not always look at point estimates, but at confidence intervals. As we are also interested in the difference between men and women, we calculate two CIs - on for men, one for women - for the snapchat / instagram proportion with traditional mathematical formulas:</p>
<pre class="r"><code># calculate CIs for men and women
sex_formula_ci &lt;- snap_insta_df %&gt;%
  filter(!is.na(snap_insta)) %&gt;% 
  group_by(sex) %&gt;%  # group by sex and calculate CIs
  summarise(`proportion of instagram/ snapchat users` = count(snap_insta == &quot;Yes&quot;)/count(snap_insta %in% c(&quot;Yes&quot;,&quot;No&quot;)),
            z_critical = qnorm(0.975),
            count = n(),
            # Confidence Interval for proportion = p  +/-  z*(√p(1-p) / n)
            se_proportion = sqrt((`proportion of instagram/ snapchat users`*(1-`proportion of instagram/ snapchat users`))/count),
            margin_of_error = z_critical * se_proportion,
            `lower bound` = `proportion of instagram/ snapchat users` - margin_of_error,
            `upper bound` = `proportion of instagram/ snapchat users` + margin_of_error
  )


# print table with CIs
sex_formula_ci %&gt;%
  select(sex, `lower bound`, `proportion of instagram/ snapchat users`, `upper bound`) %&gt;% # only show relevant columns
  kbl(caption = &quot;confidence interval on proportion of instagram/snapchat users by sex&quot;) %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) # have a nice HTML table</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<caption>
(#tab:snap_insta_CI)confidence interval on proportion of instagram/snapchat users by sex
</caption>
<thead>
<tr>
<th style="text-align:left;">
sex
</th>
<th style="text-align:right;">
lower bound
</th>
<th style="text-align:right;">
proportion of instagram/ snapchat users
</th>
<th style="text-align:right;">
upper bound
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Female
</td>
<td style="text-align:right;">
0.384
</td>
<td style="text-align:right;">
0.419
</td>
<td style="text-align:right;">
0.454
</td>
</tr>
<tr>
<td style="text-align:left;">
Male
</td>
<td style="text-align:right;">
0.281
</td>
<td style="text-align:right;">
0.318
</td>
<td style="text-align:right;">
0.356
</td>
</tr>
</tbody>
</table>
<pre class="r"><code># plot CIs
ggplot(sex_formula_ci, aes(y=sex, x = `proportion of instagram/ snapchat users`, group = sex, color=sex)) +
  #draws the means
  geom_point(size = 5) +
  #draws the CI error bars
  geom_errorbar(aes(xmin=`lower bound`, xmax=`upper bound`), width=.1, size = 2) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;)+
  labs(title = &quot;Women Spend More Hours on Social Media&quot;,
       subtitle = &quot;Confidence Intervals of Instagram/Snapchat Usage&quot;)</code></pre>
<p><img src="/blog/homework2_files/figure-html/snap_insta_CI-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>We can clearly see that the data supports the view that many more women use instagram and snapchat than men do!</p>
</div>
<div id="twitter-by-education-level" class="section level2">
<h2>Twitter, by education level</h2>
<p>Wait, there is a another social media, for which we have data! Let’s have a look at Twitter! What do you think bachelor and graduate students’ usage of Twitter would be?</p>
<p>To find out, we have to clean the data first.</p>
<p>First, let’s turn <code>degree</code> from a character variable into a factor variable, in ascending order of years of education (Lt high school, High School, Junior college, Bachelor, Graduate).</p>
<p>We then create a new variable, <code>bachelor_graduate</code>, that is <em>Yes</em> if the respondent has either a <code>Bachelor</code> or <code>Graduate</code> degree, in order to distinguish bachelor/graduate students from others.</p>
<pre class="r"><code># #inspect distinct value of degree
# gss %&gt;%
#   select(degree) %&gt;%
#   distinct(degree)

gss_modify &lt;- gss %&gt;%
  # make degree a factor with the right ordering
  mutate(degree = factor(degree,level=c(&quot;Lt high school&quot;,
                                        &quot;High school&quot;,
                                        &quot;Junior college&quot;,
                                        &quot;Bachelor&quot;,
                                        &quot;Graduate&quot;)),
         # create bachelor_graduate variable
         bachelor_graduate = case_when(degree %in% c(&quot;Bachelor&quot;,&quot;Graduate&quot;) ~ &quot;Yes&quot;,
                                       is.na(degree) ~ NA_character_,
                                       TRUE ~ &quot;No&quot;)
         )</code></pre>
<p>Third, let’s calculate the overall proportion of Twitter users:</p>
<pre class="r"><code>gss_modify %&gt;% 
  # drop observations that miss information
  drop_na(c(bachelor_graduate,twitter)) %&gt;% 
  # calculate overall Twitter proportion
  summarise(`people who use Twitter` = count(twitter == &quot;Yes&quot;),
            `people who don&#39;t use Twitter` = count(twitter == &quot;No&quot;),
            `proportion of those who use Twitter` = `people who use Twitter` / (`people who use Twitter` + `people who don&#39;t use Twitter`),
            `proportion of those who don&#39;t use Twitter` = 1 - `proportion of those who use Twitter`) %&gt;%
  kbl(caption = &quot;Overall Proportion of Twitter users&quot;) %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) # have a nice HTML table</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<caption>
(#tab:bachelor_graduate_prop_2)Overall Proportion of Twitter users
</caption>
<thead>
<tr>
<th style="text-align:right;">
people who use Twitter
</th>
<th style="text-align:right;">
people who don’t use Twitter
</th>
<th style="text-align:right;">
proportion of those who use Twitter
</th>
<th style="text-align:right;">
proportion of those who don’t use Twitter
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
255
</td>
<td style="text-align:right;">
1116
</td>
<td style="text-align:right;">
0.186
</td>
<td style="text-align:right;">
0.814
</td>
</tr>
</tbody>
</table>
<p>Let’s now bring in our newly created variable <code>bachelor_graduate</code> and see how Twitter usage varies between those with a degree vs those without a degree:</p>
<pre class="r"><code>gss_modify %&gt;% 
  # drop observations that miss information
  drop_na(c(bachelor_graduate,twitter)) %&gt;% 
  group_by(bachelor_graduate) %&gt;% # group by bachelor_graduate and calculate proportions of Twitter users
  rename(`have a higher educational degree?` = bachelor_graduate) %&gt;% # have a readable name
  summarise(`people who use Twitter` = count(twitter == &quot;Yes&quot;),
            `people who don&#39;t use Twitter` = count(twitter == &quot;No&quot;),
            `proportion of those who use Twitter` = `people who use Twitter` / (`people who use Twitter` + `people who don&#39;t use Twitter`),
            `proportion of those who don&#39;t use Twitter` = 1 - `proportion of those who use Twitter`) %&gt;%
  kbl(caption = &quot;Overall Proportion of Twitter users by education level&quot;) %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) # have a nice HTML table</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<caption>
(#tab:bachelor_graduate_prop)Overall Proportion of Twitter users by education level
</caption>
<thead>
<tr>
<th style="text-align:left;">
have a higher educational degree?
</th>
<th style="text-align:right;">
people who use Twitter
</th>
<th style="text-align:right;">
people who don’t use Twitter
</th>
<th style="text-align:right;">
proportion of those who use Twitter
</th>
<th style="text-align:right;">
proportion of those who don’t use Twitter
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
141
</td>
<td style="text-align:right;">
741
</td>
<td style="text-align:right;">
0.160
</td>
<td style="text-align:right;">
0.840
</td>
</tr>
<tr>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:right;">
114
</td>
<td style="text-align:right;">
375
</td>
<td style="text-align:right;">
0.233
</td>
<td style="text-align:right;">
0.767
</td>
</tr>
</tbody>
</table>
<p>We see that students with a degree use Twitter more. But how about the confidence intervals?</p>
<p>Using the CI formula for proportions, let’s construct two 95% CIs for <code>bachelor_graduate</code> vs whether they use (Yes) and don’t (No) use twitter.</p>
<pre class="r"><code>bachelor_graduate_formula_ci &lt;- gss_modify %&gt;%
  # drop observations that miss information
  drop_na(c(bachelor_graduate, twitter)) %&gt;% 
  group_by(bachelor_graduate) %&gt;% # group by bachelor_graduate and calculate CIs
  # Confidence Interval = p  +/-  z*(√p(1-p) / n)
  summarise(`proportion of twitter users` = count(twitter == &quot;Yes&quot;) / count(twitter %in% c(&quot;Yes&quot;,&quot;No&quot;)),
            z_critical = qnorm(0.975),
            count = n(),
            se_proportion = sqrt((`proportion of twitter users`*(1-`proportion of twitter users`))/count),
            margin_of_error = z_critical * se_proportion,
            `lower CI bound` = `proportion of twitter users` - margin_of_error,
            `upper CI bound` = `proportion of twitter users` + margin_of_error
  )

# print out CIs
bachelor_graduate_formula_ci %&gt;%
  select(bachelor_graduate, `lower CI bound`, `proportion of twitter users`, `upper CI bound`) %&gt;% # only show relevant columns
  rename(`have a higher educational degree?` = bachelor_graduate) %&gt;% # have readable names
  kbl(caption = &quot;Confidence Intervals for Twitter usage&quot;) %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) # have a nice HTML table</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<caption>
(#tab:bachelor_graduate_ci)Confidence Intervals for Twitter usage
</caption>
<thead>
<tr>
<th style="text-align:left;">
have a higher educational degree?
</th>
<th style="text-align:right;">
lower CI bound
</th>
<th style="text-align:right;">
proportion of twitter users
</th>
<th style="text-align:right;">
upper CI bound
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
0.136
</td>
<td style="text-align:right;">
0.160
</td>
<td style="text-align:right;">
0.184
</td>
</tr>
<tr>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:right;">
0.196
</td>
<td style="text-align:right;">
0.233
</td>
<td style="text-align:right;">
0.271
</td>
</tr>
</tbody>
</table>
<pre class="r"><code># plot CIs
ggplot(bachelor_graduate_formula_ci, aes(y=bachelor_graduate, 
                                         x = `proportion of twitter users`, 
                                         group = bachelor_graduate, 
                                         color=bachelor_graduate)) +
  #draws the means
  geom_point(size = 5) +
  #draws the CI error bars
  geom_errorbar(aes(xmin=`lower CI bound`, xmax=`upper CI bound`), width=.1, size = 2) +
  theme_bw() +
  theme(legend.position = &quot;none&quot;) +
  labs(y = &quot;have a higher educational degree?&quot;,
       x = &quot;Proportion of Twitter users&quot;,
       title = &quot;People with a higher education degree use Twitter more!&quot;)</code></pre>
<p><img src="/blog/homework2_files/figure-html/bachelor_graduate_ci-1.png" width="648" style="display: block; margin: auto;" />
The confidence interval for the proportion of Twitter usage is [13.6%, 18.4%] for those who do not have a degree, vs [19.6%, 27.1%] for thos who have a degree. They do not overlap.</p>
<p>Obviously, more bachelor/graduate student are using Twitter! Are you the majority?</p>
</div>
<div id="email-usage" class="section level2">
<h2>Email usage</h2>
<p>Finally, we also want to have a look at the time people spend on email. How many minutes the respondents spend on email weekly?</p>
<pre class="r"><code>gss &lt;- gss %&gt;% 
  # calculate new variable `email` (notice that either both or non of `emailhr` and `emailmin` are NA!)
  mutate(email = 60*emailhr + emailmin)

email_summary_statistics &lt;- gss %&gt;% 
  summarise(mean = mean(email, na.rm = TRUE), median = median(email, na.rm = TRUE))

# visualise distribution and mean and median
gss %&gt;% 
  ggplot(aes(x = email)) +
  geom_histogram(binwidth = 30) + # binwidth is 30 min
  theme_bw() +
  # add median and mean lines
  geom_vline(aes(xintercept = email_summary_statistics$median, colour = &#39;median&#39;), linetype = 2, size = 1) +
  geom_vline(aes(xintercept = email_summary_statistics$mean, colour = &#39;mean&#39;), linetype = 2, size = 1) +
  # change color of lines
  scale_color_manual(name = NULL, values = c(median = &quot;red&quot;, mean = &quot;blue&quot;)) +
  # show median in legend before mean
  guides(color = guide_legend(reverse = TRUE)) +
  labs(x = &quot;email usage in minutes per week&quot;,
       title = &quot;Distribution of Email Usage&quot;)</code></pre>
<p><img src="/blog/homework2_files/figure-html/email_time-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>As shown in the graph, we deal with a right skewed (unbalanced, lopsided) distribution, where the mean is farther out in the long tail than is the median.</p>
<p>Therefore the median is usually preferred to other measures of central tendency when your data set is skewed. The median is a better measure of the typical amount of time Americans spend on email weekly.</p>
<p>How about the confidence interval of email usage? Let’s take a look.</p>
<pre class="r"><code># seed set above

# bootstrap for MEAN email minutes
boot_email &lt;- gss %&gt;%
  # Specify the variable of interest
  specify(response = email) %&gt;%
  
  # Generate a bunch of bootstrap samples
  generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;%
  
  # Find the median of each sample
  calculate(stat = &quot;mean&quot;)

percentile_ci &lt;- boot_email %&gt;%
  get_ci(level = 0.95, type = &quot;percentile&quot;)

# print confidence interval
percentile_ci %&gt;% 
  mutate(lower_emailhr = lower_ci %/% 60, 
         lower_emailmin = round(lower_ci %% 60),
         upper_emailhr = upper_ci %/% 60, 
         upper_emailmin = round(upper_ci %% 60),
         `lower bound of average email usage` = paste(lower_emailhr, &quot;hr, &quot;, lower_emailmin, &quot;min&quot;),
         `upper bound of average email usage` = paste(upper_emailhr, &quot;hr, &quot;, upper_emailmin, &quot;min&quot;)) %&gt;% 
  select(`lower bound of average email usage`, `upper bound of average email usage`) %&gt;% # only show relevant columns
  kbl(caption = &quot;Confidence interval for weekly email usage&quot;) %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) # have a nice HTML table</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<caption>
(#tab:email_boot_ci)Confidence interval for weekly email usage
</caption>
<thead>
<tr>
<th style="text-align:left;">
lower bound of average email usage
</th>
<th style="text-align:left;">
upper bound of average email usage
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
6 hr, 26 min
</td>
<td style="text-align:left;">
7 hr, 30 min
</td>
</tr>
</tbody>
</table>
<pre class="r"><code># visualise confidence interval
ggplot(boot_email, aes(x = stat)) +
  geom_histogram(bins = 20) +
  labs(title= &quot;Bootstrap distribution of means&quot;) +
  geom_vline(xintercept = percentile_ci$lower_ci, colour = &#39;orange&#39;, linetype = 2, size = 1.2) +
  geom_vline(xintercept = percentile_ci$upper_ci, colour = &#39;orange&#39;, linetype = 2, size = 1.2) +
  theme_bw()</code></pre>
<p><img src="/blog/homework2_files/figure-html/email_boot_ci-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>We can find the confidence interval of weekly time spend on email under 95% is [6 hr 26 min, 7 hr 30 min]. Americans spend around 1 hour per day on email!
However, as we have seen in the distribution plot, this is probably only due to some people spending the whole day emailing, while others only check their mails once in a while.</p>
<p>We would expect a 99% confidence interval to be wider than the interval calculated because to be more confident that the true population value falls within the interval we will need to allow more potential values within the interval.</p>
</div>
</div>
<div id="trumps-approval-margins" class="section level1">
<h1>Trump’s Approval Margins</h1>
<p>As we saw in class, fivethirtyeight.com has detailed data on <a href="https://projects.fivethirtyeight.com/trump-approval-ratings">all polls that track the president’s approval</a>. Let’s see what we can learn from the data.</p>
<p>To do this, we first have to load the data:</p>
<pre class="r"><code># Import approval polls data
approval_polllist &lt;- read_csv(here::here(&#39;project_data&#39;, &#39;approval_polllist.csv&#39;))

approval_polllist &lt;- approval_polllist %&gt;% 
  # correctly interpret dates and timestamps (datetimes) with the help of lubridate
  mutate(modeldate = mdy(modeldate),
         startdate = mdy(startdate),
         enddate = mdy(enddate),
         createddate = mdy(createddate),
         timestamp = parse_date_time(timestamp, orders=&quot;hms dmy&quot;)
         )

glimpse(approval_polllist)</code></pre>
<pre><code>## Rows: 14,533
## Columns: 22
## $ president           &lt;chr&gt; &quot;Donald Trump&quot;, &quot;Donald Trump&quot;, &quot;Donald Trump&quot;,...
## $ subgroup            &lt;chr&gt; &quot;All polls&quot;, &quot;All polls&quot;, &quot;All polls&quot;, &quot;All pol...
## $ modeldate           &lt;date&gt; 2020-08-29, 2020-08-29, 2020-08-29, 2020-08-29...
## $ startdate           &lt;date&gt; 2017-01-20, 2017-01-20, 2017-01-20, 2017-01-21...
## $ enddate             &lt;date&gt; 2017-01-22, 2017-01-22, 2017-01-24, 2017-01-23...
## $ pollster            &lt;chr&gt; &quot;Gallup&quot;, &quot;Morning Consult&quot;, &quot;Ipsos&quot;, &quot;Gallup&quot;,...
## $ grade               &lt;chr&gt; &quot;B&quot;, &quot;B/C&quot;, &quot;B-&quot;, &quot;B&quot;, &quot;B&quot;, &quot;C+&quot;, &quot;B-&quot;, &quot;B+&quot;, &quot;...
## $ samplesize          &lt;dbl&gt; 1500, 1992, 1632, 1500, 1500, 1500, 1651, 1190,...
## $ population          &lt;chr&gt; &quot;a&quot;, &quot;rv&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;lv&quot;, &quot;a&quot;, &quot;rv&quot;, &quot;a&quot;,...
## $ weight              &lt;dbl&gt; 0.262, 0.680, 0.153, 0.243, 0.227, 0.200, 0.142...
## $ influence           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ approve             &lt;dbl&gt; 45.0, 46.0, 42.1, 45.0, 46.0, 57.0, 42.3, 36.0,...
## $ disapprove          &lt;dbl&gt; 45.0, 37.0, 45.2, 46.0, 45.0, 43.0, 45.8, 44.0,...
## $ adjusted_approve    &lt;dbl&gt; 45.8, 45.3, 43.2, 45.8, 46.8, 51.6, 43.4, 37.7,...
## $ adjusted_disapprove &lt;dbl&gt; 43.6, 37.8, 43.9, 44.6, 43.6, 44.4, 44.5, 42.8,...
## $ multiversions       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,...
## $ tracking            &lt;lgl&gt; TRUE, NA, TRUE, TRUE, TRUE, TRUE, TRUE, NA, NA,...
## $ url                 &lt;chr&gt; &quot;http://www.gallup.com/poll/201617/gallup-daily...
## $ poll_id             &lt;dbl&gt; 49253, 49249, 49426, 49262, 49236, 49266, 49425...
## $ question_id         &lt;dbl&gt; 77265, 77261, 77599, 77274, 77248, 77278, 77598...
## $ createddate         &lt;date&gt; 2017-01-23, 2017-01-23, 2017-03-01, 2017-01-24...
## $ timestamp           &lt;dttm&gt; 2020-08-29 13:38:37, 2020-08-29 13:38:37, 2020...</code></pre>
<div id="create-a-plot" class="section level2">
<h2>Create a plot</h2>
<p>As a next step, we calculate the average net approval rate (approve - disapprove) for each week since he got into office.</p>
<p>Then, we can plot this net approval alongside 95% confidence intervals.</p>
<pre class="r"><code># watch out for the chunk options!! (fig.height and fig.width)

# wrangle the data and calculate the CIs
approval_polllist_aggr &lt;- approval_polllist %&gt;% 
  # calculate the approval rate and get year and week
  mutate(approval_rate = approve - disapprove,
         year = factor(year(enddate)),
         week = isoweek(enddate)) %&gt;% 
  # group by year and week and calculate the CI values
  group_by(year, week) %&gt;% 
  summarise(average_approval_rate = mean(approval_rate), # calculate average approval rate per week
            SD = sd(approval_rate), # calculate SD
            count = n(), # calculate count
            t_critical = qt(0.975, count - 1), # get t-critical value with (count-1) degrees of freedom
            SE =  SD/sqrt(count), # calculate standard error
            margin_of_error = t_critical * SE, # calculate margin of error
            lower_ci = average_approval_rate - margin_of_error, # calculate lower bound of CI
            upper_ci = average_approval_rate + margin_of_error) # calculate upper bound of CI

# reproduce the plot
ggplot(approval_polllist_aggr, aes(x = week, color = year, fill = year)) +
  geom_line(aes(y = average_approval_rate)) + # add line for the average approval
  geom_point(aes(y = average_approval_rate)) + # add points for the average approval
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci),alpha=0.1) + # add the CI ribbon
  geom_hline(aes(yintercept = 0), color = &quot;orange&quot;) + # add the horizontal line
  facet_wrap(~year) + # faceting by year
  theme_bw() + # nice theme
  labs(y = &quot;Average Net Approval (%)&quot;,
       x = &quot;Week of the year&quot;,
       title = &quot;Estimating Net Approval (approve-disapprove) for Donald Trump&quot;,
       subtitle = &quot;Weekly average of all polls&quot;) +
  scale_x_continuous(breaks = c(0, 13, 26, 39, 52)) + # specific breaks
  scale_y_continuous(breaks = c(-20, -17.5, -15, -12.5, -10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5)) + # specific breaks
  theme(legend.position = &quot;none&quot;, # delete legend
        axis.title = element_text(size = 15.5), # change size of axis titles,
        axis.text = element_text(size = 13), # changes size of axis labels,
        strip.text = element_text(size = 14), # change size of facet titles
        plot.subtitle = element_text(size = 15), # change size of plot subtitle
        plot.title = element_text(size = 19)) # change size of plot title</code></pre>
<p><img src="/blog/homework2_files/figure-html/trump_margins_recreation-1.png" width="1440" style="display: block; margin: auto;" /></p>
<p>Original Plot:</p>
<p><img src="D:/LBS/academy/statistics with R/my_website_project/my_website/images/trump_approval_margin.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="compare-confidence-intervals" class="section level2">
<h2>Compare Confidence Intervals</h2>
<p>Let’s have a deeper look and compare the confidence intervals for <code>week 15</code> (6-12 April 2020) and <code>week 34</code> (17-23 August 2020):</p>
<pre class="r"><code>approval_polllist_aggr %&gt;% 
  filter(week %in% c(15, 34), year == 2020) %&gt;% 
  kbl() %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) # have a nice HTML table</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
year
</th>
<th style="text-align:right;">
week
</th>
<th style="text-align:right;">
average_approval_rate
</th>
<th style="text-align:right;">
SD
</th>
<th style="text-align:right;">
count
</th>
<th style="text-align:right;">
t_critical
</th>
<th style="text-align:right;">
SE
</th>
<th style="text-align:right;">
margin_of_error
</th>
<th style="text-align:right;">
lower_ci
</th>
<th style="text-align:right;">
upper_ci
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
2020
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
-7.72
</td>
<td style="text-align:right;">
3.75
</td>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
1.99
</td>
<td style="text-align:right;">
0.419
</td>
<td style="text-align:right;">
0.834
</td>
<td style="text-align:right;">
-8.55
</td>
<td style="text-align:right;">
-6.88
</td>
</tr>
<tr>
<td style="text-align:left;">
2020
</td>
<td style="text-align:right;">
34
</td>
<td style="text-align:right;">
-11.77
</td>
<td style="text-align:right;">
7.79
</td>
<td style="text-align:right;">
69
</td>
<td style="text-align:right;">
2.00
</td>
<td style="text-align:right;">
0.938
</td>
<td style="text-align:right;">
1.871
</td>
<td style="text-align:right;">
-13.64
</td>
<td style="text-align:right;">
-9.90
</td>
</tr>
</tbody>
</table>
<p>We can clearly see, that the confidence interval for week 34 is much wider, i.e. the margin of error is much bigger.
This is due to the following reasons:</p>
<ol style="list-style-type: decimal">
<li>We have less observations (count is lower)</li>
<li>The standard deviation for week 34 is higher, meaning that different polls don’t really agree on a approval rate</li>
<li>These two factors together lead to a higher standard error and a higher t_critical, and thus to a higher margin of error</li>
</ol>
</div>
</div>
<div id="gapminder-revisited" class="section level1">
<h1>Gapminder revisited</h1>
<p>Recall the <code>gapminder</code> data frame from the gapminder package. That data frame contains just six columns from the larger <a href="https://www.gapminder.org/data/">data in Gapminder World</a>. In this part, we will join a few dataframes with more data than the ‘gapminder’ package. They are</p>
<ul>
<li>HIV prevalence (adults_with_hiv_percent_age_15_49.csv): The estimated number of people living with HIV per 100 population of age group 15-49.</li>
<li>Life expectancy at birth (life_expectancy_years.csv)</li>
<li>The World Bank’s data of GDP per capita in constant 2010 US$, Female fertility <em>(The number of babies per woman)</em>, Primary school enrollment <em>(% of children attending primary school)</em>, Mortality rate <em>(for under 5, per 1000 live births)</em>.</li>
</ul>
<p>Firstly, we download the raw data.</p>
<pre class="r"><code># load gapminder HIV data
hiv &lt;- read_csv(here::here(&quot;project_data&quot;,&quot;adults_with_hiv_percent_age_15_49.csv&quot;))
life_expectancy &lt;- read_csv(here::here(&quot;project_data&quot;,&quot;life_expectancy_years.csv&quot;))

# get World bank data using wbstats
indicators &lt;- c(&quot;SP.DYN.TFRT.IN&quot;,&quot;SE.PRM.NENR&quot;, &quot;SH.DYN.MORT&quot;, &quot;NY.GDP.PCAP.KD&quot;)

library(wbstats)

worldbank_data &lt;- wb_data(country=&quot;countries_only&quot;, #countries only- no aggregates like Latin America, Europe, etc.
                          indicator = indicators, 
                          start_date = 1960, 
                          end_date = 2016) %&gt;% 
                  rename(fertility = SP.DYN.TFRT.IN,
                         GDP_cap = NY.GDP.PCAP.KD,
                         prim_enrol = SE.PRM.NENR,
                         mortality = SH.DYN.MORT) # rename the col to make it more readable

# get a dataframe of information regarding countries, indicators, sources, regions, indicator topics, lending types, income levels,  from the World Bank API 
countries &lt;-  wbstats::wb_cachelist$countries</code></pre>
<p>Then, let’s join the 3 dataframes (life_expectancy, worldbank_data, and HIV) into one.</p>
<p>Since each dataset varies in the countries and years they covered, the method used here is full join in order NOT to delete any information. However if we keep all data, there might be NAs, but we can later on still filter out NAs, but ONLY FOR THE COLUMNS WE ANALYSE!</p>
<p>In addition, for further grouping analysis purpose, we also match additional information to each country using a left join.
In this case, it is a left join, because we do only need additional information for the countries we already have in our dataset.</p>
<pre class="r"><code>library(countrycode)
library(gapminder)

# tidy data

life_expectancy_long &lt;- life_expectancy %&gt;%
  # bring into long format
  pivot_longer(cols = &#39;1800&#39;:&#39;2100&#39;, names_to = &quot;date&quot;, values_to = &quot;life_exp&quot;) %&gt;%
  mutate(date = as.double(date),
         iso3c = countrycode(country, # get iso3c code
                             origin = &#39;country.name&#39;,
                             destination = &#39;iso3c&#39;))

hiv_long &lt;- hiv %&gt;%
  # bring into long format
  pivot_longer(cols = &#39;1979&#39;:&#39;2011&#39;, names_to = &quot;date&quot;, values_to = &quot;hiv_prev&quot;) %&gt;%
  mutate(date = as.double(date),
         iso3c = countrycode(country, # get iso3c code
                             origin = &#39;country.name&#39;, 
                             destination = &#39;iso3c&#39;))

#join the 3 dataframes (life_expectancy, worldbank_data, and HIV) into one
joined_df &lt;- full_join(subset(life_expectancy_long, select = -c(country)),
                       full_join(subset(hiv_long, select = -c(country)),
                                 subset(worldbank_data, select = -c(iso2c),
                                 by = c(&quot;iso3c&quot;,&quot;date&quot;))),
                       by = c(&quot;iso3c&quot;,&quot;date&quot;))

# add additional info via left join
joined_df_region &lt;- joined_df %&gt;% 
  left_join(subset(countries, select = -c(country)), by = &quot;iso3c&quot;)</code></pre>
<p>Now we have all the data in hand, including HIV prevalence, Life expectancy, GDP per capita, Female fertility, Primary school enrollment, and Mortality rate. Let’s check they relationships one by one.</p>
<div id="hiv-prevalence-and-life-expectancy-by-region" class="section level2">
<h2>HIV prevalence and life expectancy, by region</h2>
<p>Our first question would be - What is the relationship between HIV prevalence and life expectancy?</p>
<pre class="r"><code>joined_df %&gt;%
  drop_na(c(hiv_prev,life_exp)) %&gt;%
  ggplot(aes(x = hiv_prev/100, y = life_exp)) + # hiv_prevalence is &quot;The estimated number of people living with HIV per 100 population of age group 15-49.&quot;
  geom_point(alpha = 0.2) +
  geom_smooth()+ # added smoothed line
  scale_x_continuous(labels = scales::percent) + # scale with percentages
  theme_bw() + 
  labs(title = &quot;Lower life expectancy with higher HIV prevalence&quot;,
       subtitle = &quot;Life expectancy in different countries and years by HIV prevalence&quot;,
       x = &quot;HIV prevalence in age group 15-49&quot;,
       y = &quot;life expectancy&quot;,
       caption = &quot;Source: World Bank&quot;)+
  NULL</code></pre>
<p><img src="/blog/homework2_files/figure-html/hiv_life_exp-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>joined_df_region %&gt;%
  drop_na(c(hiv_prev,life_exp)) %&gt;%
  filter(region %in% c(&quot;Latin America &amp; Caribbean&quot;, &quot;Sub-Saharan Africa&quot;)) %&gt;%
  ggplot(aes(x = hiv_prev/100, y = life_exp)) + # hiv_prevalence is &quot;The estimated number of people living with HIV per 100 population of age group 15-49.&quot;
  geom_point(alpha = 0.2) +
  geom_smooth()+ # add smoothed line
  scale_x_continuous(labels = scales::percent) + # scale with percentages
  theme_bw() + 
  labs(title = &quot;Lower life expectancy with higher HIV prevalence&quot;,
       subtitle = &quot;Life expectancy in different countries and years by HIV prevalence&quot;,
       x = &quot;HIV prevalence in age group 15-49&quot;,
       y = &quot;life expectancy&quot;,
       caption = &quot;Source: World Bank&quot;)+
  facet_wrap(~region, scales = &quot;free&quot;)+
  NULL</code></pre>
<p><img src="/blog/homework2_files/figure-html/hiv_life_exp-2.png" width="648" style="display: block; margin: auto;" /></p>
<p>From a general view, we know in the range between 0%-7% of HIV prevalence, the life expectancy decrease pretty quickly as HIV prevalence raises. When HIV prevalence exceed 7%, the life expectancy doesn’t significantly continue to decrease, because of few observations and the fact that ~50 is already the worst life expectancy for HIV.</p>
<p>Zooming in to see what’s going on for specific regions, the results are similar.</p>
</div>
<div id="fertility-rate-and-gdp-per-capita-by-region" class="section level2">
<h2>Fertility rate and GDP per capita, by region</h2>
<p>We’re also curious about the the relationship between fertility rate and GDP per capita. Let’s take a look.</p>
<pre class="r"><code>joined_df %&gt;%
  drop_na(c(fertility, GDP_cap)) %&gt;%
  ggplot(aes(x = fertility, y = GDP_cap)) +
  geom_point(alpha = 0.2) +
  geom_smooth()+ # add smoothed line
  scale_y_log10() + # logarithmic scale
  theme_bw() + 
  labs(title = &quot;Lower GDP per capita with higher fertility&quot;,
       subtitle = &quot;GDP per capita in different countries and years by fertility&quot;,
       x = &quot;fertility (no. of babies per woman)&quot;,
       y = &quot;GDP per capita (log scale)&quot;,
       caption = &quot;Source: World Bank&quot;)+
  NULL</code></pre>
<p><img src="/blog/homework2_files/figure-html/fertility_GDP_cap-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>joined_df_region %&gt;%
  drop_na(c(fertility, GDP_cap)) %&gt;%
  ggplot(aes(x = fertility, y = GDP_cap)) + 
  geom_point(alpha = 0.2) +
  geom_smooth() + # add smoothed line
  scale_y_log10() + # logarithmic scale
  theme_bw() + 
  labs(title = &quot;Lower GDP per capita with higher fertility&quot;,
       subtitle = &quot;GDP per capita in different countries and years by fertility&quot;,
       x = &quot;fertility (no. of babies per woman)&quot;,
       y = &quot;GDP per capita (log scale)&quot;,
       caption = &quot;Source: World Bank&quot;)+
  facet_wrap(~region, scales = &quot;free&quot;)+ # faceting by region
  NULL</code></pre>
<p><img src="/blog/homework2_files/figure-html/fertility_GDP_cap-2.png" width="648" style="display: block; margin: auto;" /></p>
<p>Not surprisingly, the lower GDP per capita, the higher fertility. There are complicated economics and sociology reasons behind it, such as hoping for demographic dividend to drive the GDP, and stronger social welfare system decreasing the need of children support when retired.</p>
<p>For regions having more 3rd world countries, the trend are more rapid, corresponding to their economics growth.</p>
</div>
<div id="missing-hiv-data-by-region" class="section level2">
<h2>Missing HIV data by region</h2>
<p>When analyzing the HIV prevalence, we found a lot missing values. Which regions have the most observations with missing HIV data?</p>
<pre class="r"><code>hiv_long_region &lt;- left_join(hiv_long, 
                             countries,
                             by = &quot;iso3c&quot;)

hiv_long_region %&gt;%
  group_by(region) %&gt;%
  summarise(num_na = sum(is.na(hiv_prev))) %&gt;%
  ggplot(aes(x = num_na, y = reorder(region,num_na))) +
  geom_col() +
  theme_bw() + 
  labs(y = &quot;&quot;, 
       x = &quot;Count of observations with missing HIV data&quot;,
       title = &quot;Observations with missing HIV data by region&quot;)</code></pre>
<p><img src="/blog/homework2_files/figure-html/missing_hiv_Data-1.png" width="648" style="display: block; margin: auto;" /></p>
</div>
<div id="change-of-mortality-rate-for-under-5-by-region" class="section level2">
<h2>Change of mortality rate for under 5, by region</h2>
<p>How has mortality rate for under 5 changed by region? We plot the overall picture and the top/bottom five countries in each region.</p>
<pre class="r"><code>joined_df_region %&gt;%
  drop_na(mortality) %&gt;%
  ggplot(aes(x = date, y = mortality)) +
  theme_bw() +
  geom_line(aes(group = iso3c, color = iso3c)) + # add lines
  theme(legend.position = &quot;none&quot;) +
  labs(title = &quot;Mortality for under 5 dropped in all regions!&quot;,
     subtitle = &quot;Development of mortality (under 5) in different regions over the past years&quot;,
     x = &quot;&quot;,
     y = &quot;mortality for under 5, per 1000 live births&quot;) +
  facet_wrap(~region) + # faceting by region
  NULL</code></pre>
<p><img src="/blog/homework2_files/figure-html/mortality_rate_change-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code># calculate improvement in mortality per country
mortality_ranking &lt;- joined_df_region %&gt;%
  drop_na(mortality) %&gt;%
  arrange(iso3c, date) %&gt;%
  group_by(region, country) %&gt;%
  summarise(early_m = first(mortality), # get the earliest recorded value in mortality
            latest_m = last(mortality), # get the latest recorded value in mortality
            improvement_m =  - (latest_m - early_m)/early_m) %&gt;% # calculate difference / improvement
  arrange(region, desc(improvement_m))

# Top 5

mortality_ranking %&gt;% 
  top_n(5, improvement_m) %&gt;%
  select(&#39;region&#39;,&#39;country&#39;,&#39;improvement_m&#39;) %&gt;%
  rename(&#39;top 5 countries&#39; = country,
         &#39;mortality improvement&#39; = improvement_m) %&gt;% # have readable names
  kbl() %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) # have a nice HTML table</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
region
</th>
<th style="text-align:left;">
top 5 countries
</th>
<th style="text-align:right;">
mortality improvement
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
East Asia &amp; Pacific
</td>
<td style="text-align:left;">
Korea, Rep. 
</td>
<td style="text-align:right;">
0.970
</td>
</tr>
<tr>
<td style="text-align:left;">
East Asia &amp; Pacific
</td>
<td style="text-align:left;">
Singapore
</td>
<td style="text-align:right;">
0.943
</td>
</tr>
<tr>
<td style="text-align:left;">
East Asia &amp; Pacific
</td>
<td style="text-align:left;">
Japan
</td>
<td style="text-align:right;">
0.932
</td>
</tr>
<tr>
<td style="text-align:left;">
East Asia &amp; Pacific
</td>
<td style="text-align:left;">
Thailand
</td>
<td style="text-align:right;">
0.930
</td>
</tr>
<tr>
<td style="text-align:left;">
East Asia &amp; Pacific
</td>
<td style="text-align:left;">
China
</td>
<td style="text-align:right;">
0.916
</td>
</tr>
<tr>
<td style="text-align:left;">
Europe &amp; Central Asia
</td>
<td style="text-align:left;">
Portugal
</td>
<td style="text-align:right;">
0.969
</td>
</tr>
<tr>
<td style="text-align:left;">
Europe &amp; Central Asia
</td>
<td style="text-align:left;">
Turkey
</td>
<td style="text-align:right;">
0.953
</td>
</tr>
<tr>
<td style="text-align:left;">
Europe &amp; Central Asia
</td>
<td style="text-align:left;">
Italy
</td>
<td style="text-align:right;">
0.934
</td>
</tr>
<tr>
<td style="text-align:left;">
Europe &amp; Central Asia
</td>
<td style="text-align:left;">
Cyprus
</td>
<td style="text-align:right;">
0.932
</td>
</tr>
<tr>
<td style="text-align:left;">
Europe &amp; Central Asia
</td>
<td style="text-align:left;">
Poland
</td>
<td style="text-align:right;">
0.928
</td>
</tr>
<tr>
<td style="text-align:left;">
Latin America &amp; Caribbean
</td>
<td style="text-align:left;">
Chile
</td>
<td style="text-align:right;">
0.951
</td>
</tr>
<tr>
<td style="text-align:left;">
Latin America &amp; Caribbean
</td>
<td style="text-align:left;">
Peru
</td>
<td style="text-align:right;">
0.934
</td>
</tr>
<tr>
<td style="text-align:left;">
Latin America &amp; Caribbean
</td>
<td style="text-align:left;">
El Salvador
</td>
<td style="text-align:right;">
0.920
</td>
</tr>
<tr>
<td style="text-align:left;">
Latin America &amp; Caribbean
</td>
<td style="text-align:left;">
Ecuador
</td>
<td style="text-align:right;">
0.916
</td>
</tr>
<tr>
<td style="text-align:left;">
Latin America &amp; Caribbean
</td>
<td style="text-align:left;">
Antigua and Barbuda
</td>
<td style="text-align:right;">
0.914
</td>
</tr>
<tr>
<td style="text-align:left;">
Middle East &amp; North Africa
</td>
<td style="text-align:left;">
Oman
</td>
<td style="text-align:right;">
0.967
</td>
</tr>
<tr>
<td style="text-align:left;">
Middle East &amp; North Africa
</td>
<td style="text-align:left;">
Bahrain
</td>
<td style="text-align:right;">
0.963
</td>
</tr>
<tr>
<td style="text-align:left;">
Middle East &amp; North Africa
</td>
<td style="text-align:left;">
United Arab Emirates
</td>
<td style="text-align:right;">
0.961
</td>
</tr>
<tr>
<td style="text-align:left;">
Middle East &amp; North Africa
</td>
<td style="text-align:left;">
Libya
</td>
<td style="text-align:right;">
0.954
</td>
</tr>
<tr>
<td style="text-align:left;">
Middle East &amp; North Africa
</td>
<td style="text-align:left;">
Saudi Arabia
</td>
<td style="text-align:right;">
0.951
</td>
</tr>
<tr>
<td style="text-align:left;">
North America
</td>
<td style="text-align:left;">
Canada
</td>
<td style="text-align:right;">
0.840
</td>
</tr>
<tr>
<td style="text-align:left;">
North America
</td>
<td style="text-align:left;">
United States
</td>
<td style="text-align:right;">
0.777
</td>
</tr>
<tr>
<td style="text-align:left;">
South Asia
</td>
<td style="text-align:left;">
Maldives
</td>
<td style="text-align:right;">
0.969
</td>
</tr>
<tr>
<td style="text-align:left;">
South Asia
</td>
<td style="text-align:left;">
Sri Lanka
</td>
<td style="text-align:right;">
0.913
</td>
</tr>
<tr>
<td style="text-align:left;">
South Asia
</td>
<td style="text-align:left;">
Nepal
</td>
<td style="text-align:right;">
0.893
</td>
</tr>
<tr>
<td style="text-align:left;">
South Asia
</td>
<td style="text-align:left;">
Bhutan
</td>
<td style="text-align:right;">
0.887
</td>
</tr>
<tr>
<td style="text-align:left;">
South Asia
</td>
<td style="text-align:left;">
Bangladesh
</td>
<td style="text-align:right;">
0.863
</td>
</tr>
<tr>
<td style="text-align:left;">
Sub-Saharan Africa
</td>
<td style="text-align:left;">
Cabo Verde
</td>
<td style="text-align:right;">
0.900
</td>
</tr>
<tr>
<td style="text-align:left;">
Sub-Saharan Africa
</td>
<td style="text-align:left;">
Mauritius
</td>
<td style="text-align:right;">
0.861
</td>
</tr>
<tr>
<td style="text-align:left;">
Sub-Saharan Africa
</td>
<td style="text-align:left;">
Seychelles
</td>
<td style="text-align:right;">
0.858
</td>
</tr>
<tr>
<td style="text-align:left;">
Sub-Saharan Africa
</td>
<td style="text-align:left;">
Malawi
</td>
<td style="text-align:right;">
0.858
</td>
</tr>
<tr>
<td style="text-align:left;">
Sub-Saharan Africa
</td>
<td style="text-align:left;">
Gambia, The
</td>
<td style="text-align:right;">
0.840
</td>
</tr>
</tbody>
</table>
<pre class="r"><code># Bottom 5

mortality_ranking %&gt;% 
  top_n(-5, improvement_m) %&gt;%
  select(&#39;region&#39;,&#39;country&#39;,&#39;improvement_m&#39;) %&gt;%
  arrange(region, improvement_m) %&gt;%
  rename(&#39;bottom 5 countries&#39; = country,
         &#39;mortality improvement&#39; = improvement_m) %&gt;% # have readable names
  kbl() %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) # have a nice HTML table</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
region
</th>
<th style="text-align:left;">
bottom 5 countries
</th>
<th style="text-align:right;">
mortality improvement
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
East Asia &amp; Pacific
</td>
<td style="text-align:left;">
Micronesia, Fed. Sts.
</td>
<td style="text-align:right;">
0.425
</td>
</tr>
<tr>
<td style="text-align:left;">
East Asia &amp; Pacific
</td>
<td style="text-align:left;">
Korea, Dem. People’s Rep. 
</td>
<td style="text-align:right;">
0.430
</td>
</tr>
<tr>
<td style="text-align:left;">
East Asia &amp; Pacific
</td>
<td style="text-align:left;">
Palau
</td>
<td style="text-align:right;">
0.475
</td>
</tr>
<tr>
<td style="text-align:left;">
East Asia &amp; Pacific
</td>
<td style="text-align:left;">
Nauru
</td>
<td style="text-align:right;">
0.543
</td>
</tr>
<tr>
<td style="text-align:left;">
East Asia &amp; Pacific
</td>
<td style="text-align:left;">
Tuvalu
</td>
<td style="text-align:right;">
0.672
</td>
</tr>
<tr>
<td style="text-align:left;">
Europe &amp; Central Asia
</td>
<td style="text-align:left;">
Monaco
</td>
<td style="text-align:right;">
0.649
</td>
</tr>
<tr>
<td style="text-align:left;">
Europe &amp; Central Asia
</td>
<td style="text-align:left;">
Turkmenistan
</td>
<td style="text-align:right;">
0.682
</td>
</tr>
<tr>
<td style="text-align:left;">
Europe &amp; Central Asia
</td>
<td style="text-align:left;">
Slovak Republic
</td>
<td style="text-align:right;">
0.718
</td>
</tr>
<tr>
<td style="text-align:left;">
Europe &amp; Central Asia
</td>
<td style="text-align:left;">
Ukraine
</td>
<td style="text-align:right;">
0.728
</td>
</tr>
<tr>
<td style="text-align:left;">
Europe &amp; Central Asia
</td>
<td style="text-align:left;">
Moldova
</td>
<td style="text-align:right;">
0.761
</td>
</tr>
<tr>
<td style="text-align:left;">
Latin America &amp; Caribbean
</td>
<td style="text-align:left;">
Bahamas, The
</td>
<td style="text-align:right;">
0.539
</td>
</tr>
<tr>
<td style="text-align:left;">
Latin America &amp; Caribbean
</td>
<td style="text-align:left;">
Guyana
</td>
<td style="text-align:right;">
0.651
</td>
</tr>
<tr>
<td style="text-align:left;">
Latin America &amp; Caribbean
</td>
<td style="text-align:left;">
Suriname
</td>
<td style="text-align:right;">
0.656
</td>
</tr>
<tr>
<td style="text-align:left;">
Latin America &amp; Caribbean
</td>
<td style="text-align:left;">
Venezuela, RB
</td>
<td style="text-align:right;">
0.694
</td>
</tr>
<tr>
<td style="text-align:left;">
Latin America &amp; Caribbean
</td>
<td style="text-align:left;">
Trinidad and Tobago
</td>
<td style="text-align:right;">
0.717
</td>
</tr>
<tr>
<td style="text-align:left;">
Middle East &amp; North Africa
</td>
<td style="text-align:left;">
Djibouti
</td>
<td style="text-align:right;">
0.635
</td>
</tr>
<tr>
<td style="text-align:left;">
Middle East &amp; North Africa
</td>
<td style="text-align:left;">
West Bank and Gaza
</td>
<td style="text-align:right;">
0.804
</td>
</tr>
<tr>
<td style="text-align:left;">
Middle East &amp; North Africa
</td>
<td style="text-align:left;">
Malta
</td>
<td style="text-align:right;">
0.824
</td>
</tr>
<tr>
<td style="text-align:left;">
Middle East &amp; North Africa
</td>
<td style="text-align:left;">
Iraq
</td>
<td style="text-align:right;">
0.851
</td>
</tr>
<tr>
<td style="text-align:left;">
Middle East &amp; North Africa
</td>
<td style="text-align:left;">
Yemen, Rep. 
</td>
<td style="text-align:right;">
0.861
</td>
</tr>
<tr>
<td style="text-align:left;">
North America
</td>
<td style="text-align:left;">
United States
</td>
<td style="text-align:right;">
0.777
</td>
</tr>
<tr>
<td style="text-align:left;">
North America
</td>
<td style="text-align:left;">
Canada
</td>
<td style="text-align:right;">
0.840
</td>
</tr>
<tr>
<td style="text-align:left;">
South Asia
</td>
<td style="text-align:left;">
Pakistan
</td>
<td style="text-align:right;">
0.708
</td>
</tr>
<tr>
<td style="text-align:left;">
South Asia
</td>
<td style="text-align:left;">
Afghanistan
</td>
<td style="text-align:right;">
0.804
</td>
</tr>
<tr>
<td style="text-align:left;">
South Asia
</td>
<td style="text-align:left;">
India
</td>
<td style="text-align:right;">
0.831
</td>
</tr>
<tr>
<td style="text-align:left;">
South Asia
</td>
<td style="text-align:left;">
Bangladesh
</td>
<td style="text-align:right;">
0.863
</td>
</tr>
<tr>
<td style="text-align:left;">
South Asia
</td>
<td style="text-align:left;">
Bhutan
</td>
<td style="text-align:right;">
0.887
</td>
</tr>
<tr>
<td style="text-align:left;">
Sub-Saharan Africa
</td>
<td style="text-align:left;">
Somalia
</td>
<td style="text-align:right;">
0.346
</td>
</tr>
<tr>
<td style="text-align:left;">
Sub-Saharan Africa
</td>
<td style="text-align:left;">
Chad
</td>
<td style="text-align:right;">
0.501
</td>
</tr>
<tr>
<td style="text-align:left;">
Sub-Saharan Africa
</td>
<td style="text-align:left;">
Namibia
</td>
<td style="text-align:right;">
0.511
</td>
</tr>
<tr>
<td style="text-align:left;">
Sub-Saharan Africa
</td>
<td style="text-align:left;">
Lesotho
</td>
<td style="text-align:right;">
0.515
</td>
</tr>
<tr>
<td style="text-align:left;">
Sub-Saharan Africa
</td>
<td style="text-align:left;">
Equatorial Guinea
</td>
<td style="text-align:right;">
0.541
</td>
</tr>
</tbody>
</table>
</div>
<div id="primary-school-enrollment-and-fertility-rate" class="section level2">
<h2>Primary school enrollment and fertility rate</h2>
<p>Is there a relationship between primary school enrollment and fertility rate?</p>
<pre class="r"><code>joined_df_region %&gt;%
  drop_na(c(prim_enrol,fertility)) %&gt;%
  ggplot(aes(x = prim_enrol/100, y = fertility))+
  geom_point(alpha = 0.2)+
  geom_smooth()+ # add smoothed line
  theme_bw()+
  labs(title = &quot;The more people are engaged in primary education, \nthe less is the fertility rate&quot;,
       subtitle = &quot;Fertility under different primary school enrolment rate by countries and years&quot;,
       x = &quot;primary school enrolment rate&quot;,
       y = &quot;fertility (no. of babies per woman)&quot;,
       caption = &quot;Source: World Bank&quot;) +
  scale_x_continuous(label = scales::percent) + # have percentages
  NULL</code></pre>
<p><img src="/blog/homework2_files/figure-html/primary_enrollment_fertility-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>High levels of primary school enrollment are associated with fertility rate declines. This indicates a decline in patriarchy, change in women’s familial roles and a shift to a more egalitarian family structure. It would be better for us to gain women school enrollment, because in general increases in female education mean higher status and more power for women.</p>
</div>
</div>
<div id="challenge-1-cdc-covid-19-public-use-data" class="section level1">
<h1>Challenge 1: CDC COVID-19 Public Use Data</h1>
<p>Let us revisit the <a href="https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data/vbim-akqf">CDC Covid-19 Case Surveillance Data</a>. There are well over 3 million entries of individual, de-identified patient data. Sounds great? Of course! Let’s load that data using <code>vroom</code>:</p>
<pre class="r"><code># URL link to CDC to download data
url &lt;- &quot;https://data.cdc.gov/api/views/vbim-akqf/rows.csv?accessType=DOWNLOAD&quot;

covid_data &lt;- vroom(url)%&gt;%
  clean_names()</code></pre>
<p>Replicated plots:</p>
<pre class="r"><code># watch out for the chunk options!! (fig.height and fig.width)

covid_data &lt;- covid_data %&gt;% 
  # clean death rate
  mutate(death_yn_clean = case_when(death_yn == &quot;Yes&quot; ~ &quot;Yes&quot;,
                                    death_yn == &quot;No&quot; ~ &quot;No&quot;,
                                    TRUE ~ NA_character_)
  ) %&gt;% 
  # clean age group
  mutate(age_group_clean = ifelse(age_group == &quot;Unknown&quot;, NA_character_, age_group)) %&gt;% 
  # clean sex
  mutate(sex_clean = case_when(sex == &quot;Male&quot; ~ &quot;Male&quot;,
                               sex == &quot;Female&quot; ~ &quot;Female&quot;,
                               TRUE ~ NA_character_)
  ) %&gt;% 
  # clean co-morbidities
  mutate(medcond_yn_clean = factor(case_when(medcond_yn == &quot;Yes&quot; ~ &quot;Yes&quot;,
                                             medcond_yn == &quot;No&quot; ~ &quot;No&quot;,
                                             TRUE ~ NA_character_), 
                                   levels = c(&quot;Yes&quot;, &quot;No&quot;),
                                   labels = c(&quot;With comorbidities&quot;, &quot;Without comorbidities&quot;))
  ) %&gt;% 
  # clean ICU status
  mutate(icu_yn_clean = factor(case_when(icu_yn == &quot;Yes&quot; ~ &quot;Yes&quot;,
                                         icu_yn == &quot;No&quot; ~ &quot;No&quot;,
                                         TRUE ~ NA_character_),
                               levels = c(&quot;Yes&quot;, &quot;No&quot;),
                               labels = c(&quot;Admitted to ICU&quot;, &quot;No ICU&quot;))
  )
  

# first graph
covid_data %&gt;% 
  # only work with rows we have data for
  drop_na(c(age_group_clean, sex_clean, medcond_yn_clean, death_yn_clean)) %&gt;% 
  # group by and calculate the death rate per subgroups
  group_by(age_group_clean, sex_clean, medcond_yn_clean) %&gt;% 
  summarise(n_yes = count(death_yn_clean == &quot;Yes&quot;),
            n_no = count(death_yn_clean == &quot;No&quot;),
            death_rate = n_yes / (n_yes + n_no)) %&gt;% 
  # plot the calculated death rates per subgroup
  ggplot(aes(y = age_group_clean, x = death_rate)) +
  geom_col(fill = &quot;#6B7CA4&quot;) + # set bar color
  geom_text(aes(label = round(100*death_rate, 1)), # add the labels next to the bars
            position = position_dodge(width = .9),    # move to center of bars
            hjust = -0.1, # nudge position right to bars
            size = 3) + 
  facet_grid(rows = vars(medcond_yn_clean),
             cols = vars(sex_clean)) + # faceting by sex and medcond
  scale_x_continuous(breaks = c(0, 0.2, 0.4, 0.6), labels = scales::percent) + # show as percentages and have individual breaks
  labs(title = &quot;Covid death % by age group, sex and presence of co-morbidities&quot;,
       caption = &quot;Source: CDC&quot;,
       x = NULL,
       y = NULL) +
  theme_bw() + # nice theme
  theme(axis.text = element_text(size = 6), # changes size of axis labels,
        strip.text = element_text(size = 6), # change size of facet titles
        plot.caption = element_text(size = 6), # change size of plot subtitle
        plot.title = element_text(size = 8)) # change size of plot title</code></pre>
<p><img src="/blog/homework2_files/figure-html/covid_challenge_reproduction-1.png" width="1440" style="display: block; margin: auto;" /></p>
<pre class="r"><code># second graph
covid_data %&gt;% 
  # only work with rows we have data for
  drop_na(c(age_group_clean, sex_clean, icu_yn_clean, death_yn_clean)) %&gt;% 
  # group by and calculate the death rate per subgroups
  group_by(age_group_clean, sex_clean, icu_yn_clean) %&gt;% 
  summarise(n_yes = count(death_yn_clean == &quot;Yes&quot;),
            n_no = count(death_yn_clean == &quot;No&quot;),
            death_rate = n_yes / (n_yes + n_no)) %&gt;% 
  # plot the calculated death rates per subgroup
  ggplot(aes(y = age_group_clean, x = death_rate)) +
  geom_col(fill = &quot;#FF9582&quot;) + # set bar color
  geom_text(aes(label = round(100*death_rate, 1)),# add the labels next to the bars
            position = position_dodge(width = .9), # move to center of bars
            hjust = -0.1,    # nudge position right to bars
            size = 3) + 
  facet_grid(rows = vars(icu_yn_clean), 
             cols = vars(sex_clean)) + # faceting by icu and sex
  scale_x_continuous(breaks = c(0, 0.2, 0.4, 0.6, 0.8), labels = scales::percent) + # show as percentages and have individual breaks
  labs(title = &quot;Covid death % by age group, sex and whether patient was admitted to ICU&quot;,
       caption = &quot;Source: CDC&quot;,
       x = NULL,
       y = NULL) +
  theme_bw() + # nice theme
  theme(axis.text = element_text(size = 6), # changes size of axis labels,
        strip.text = element_text(size = 6), # change size of facet titles
        plot.caption = element_text(size = 6), # change size of plot subtitle
        plot.title = element_text(size = 8)) # change size of plot title</code></pre>
<p><img src="/blog/homework2_files/figure-html/covid_challenge_reproduction-2.png" width="1440" style="display: block; margin: auto;" /></p>
<p>Original plots:</p>
<p><img src="D:/LBS/academy/statistics with R/my_website_project/my_website/images/covid_death_rate_comorbidities.png" width="100%" style="display: block; margin: auto;" /><img src="D:/LBS/academy/statistics with R/my_website_project/my_website/images/covid_death_rate_icu.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="challenge-2-excess-rentals-in-tfl-bike-sharing" class="section level1">
<h1>Challenge 2: Excess rentals in TfL bike sharing</h1>
<p>Recall the TfL data on how many bikes were hired every single day. We can get the latest data by running the following</p>
<pre class="r"><code>url &lt;- &quot;https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx&quot;

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp &lt;- tempfile(fileext = &quot;.xlsx&quot;)))</code></pre>
<pre><code>## Response [https://airdrive-secure.s3-eu-west-1.amazonaws.com/london/dataset/number-bicycle-hires/2020-08-26T09%3A19%3A21/tfl-daily-cycle-hires.xlsx?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAJJDIMAIVZJDICKHA%2F20200913%2Feu-west-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200913T182409Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=e8b471dc44aeb92fc94c697ceb3710e87ee182aa8174776b4eaf0aed91fb670e&amp;X-Amz-SignedHeaders=host]
##   Date: 2020-09-13 18:24
##   Status: 200
##   Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
##   Size: 164 kB
## &lt;ON DISK&gt;  C:\Users\Lenovo\AppData\Local\Temp\RtmpyY6aUb\file601c41e2576e.xlsx</code></pre>
<pre class="r"><code># Use read_excel to read it as dataframe
bike0 &lt;- read_excel(bike.temp,
                   sheet = &quot;Data&quot;,
                   range = cell_cols(&quot;A:B&quot;))

# change dates to get year, month, and week
bike &lt;- bike0 %&gt;% 
  clean_names() %&gt;% 
  rename (bikes_hired = number_of_bicycle_hires) %&gt;% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))</code></pre>
<p>We can easily create a facet grid that plots bikes hired by month and year:</p>
<p><img src="D:/LBS/academy/statistics with R/my_website_project/my_website/images/tfl_distributions_monthly.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Looking at May and Jun and comparing 2020 with the previous years, we can directly see the impact of the COVID pandemic!</p>
<p>Original Plot:</p>
<p><img src="D:/LBS/academy/statistics with R/my_website_project/my_website/images/tfl_monthly.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Plot Reproduction:</p>
<pre class="r"><code># data preparation

expected_rentals_df &lt;- bike %&gt;% 
  # use years 2015-2019 as reference
  filter(year %in% 2015:2019) %&gt;% 
  # calculate expected rentals (per day) per month over all years
  group_by(month) %&gt;% 
  summarise(expected_rentals = mean(bikes_hired))

excess_by_month &lt;- bike %&gt;% 
  # use years 2015-2019 as reference
  filter(year %in% 2015:2020) %&gt;% 
  # calculate actual rentals for each month for every year
  group_by(year, month) %&gt;% 
  summarise(actual_rentals = mean(bikes_hired)) %&gt;% 
  # join the expected rentals per month (over all years)
  left_join(expected_rentals_df, on = &quot;month&quot;) %&gt;% 
  # calculate excess_rentals and helper variables for the ribbon
  mutate(excess_rentals = actual_rentals - expected_rentals,
         excess_rentals_pos = ifelse(excess_rentals&gt;0, excess_rentals+expected_rentals, expected_rentals),
         excess_rentals_neg = ifelse(excess_rentals&lt;0, excess_rentals+expected_rentals, expected_rentals))


# plot graph 1
ggplot(excess_by_month, aes(x = month)) +
  # add line for expected rentals (same for all years)
  geom_line(aes(y = expected_rentals), group = 1, size = 1, color = &quot;blue&quot;) +
  # add black line for actual rentals 
  geom_line(aes(y = actual_rentals), group = 1, color = &quot;black&quot;) +
  # add red and green ribbons
  geom_ribbon(aes(ymin = expected_rentals, ymax = excess_rentals_pos, group = 1), fill = &quot;green4&quot;, alpha = 0.2) +
  geom_ribbon(aes(ymin = expected_rentals, ymax = excess_rentals_neg, group = 1), fill = &quot;red3&quot;, alpha = 0.2) +
  # faceting by year
  facet_wrap(~year) +
  theme_minimal() +
  # use specific breaks
  scale_y_continuous(breaks = c(20000, 25000, 30000, 35000, 40000)) +
  labs(y = &quot;Bike rentals&quot;,
       x = &quot;&quot;,
       title = &quot;Monthly changes in TfL bike rentals&quot;,
       subtitle = &quot;Change from monthly average shown in blue \nand calculated between 2015-2019&quot;,
       caption = &quot;Source: TfL, London Data Store&quot;) +
  theme(axis.text = element_text(size = 12), # changes size of axis labels,
        axis.title = element_text(size = 15), # changes size of axis titles,
        strip.text = element_text(size = 13), # change size of facet titles
        plot.subtitle = element_text(size = 15), # change size of plot subtitle
        plot.caption = element_text(size = 12), # change size of plot caption
        plot.title = element_text(size = 18)) # change size of plot title</code></pre>
<p><img src="/blog/homework2_files/figure-html/monthly_changes-1.png" width="1440" style="display: block; margin: auto;" /></p>
<p>Original Plot:</p>
<p><img src="D:/LBS/academy/statistics with R/my_website_project/my_website/images/tfl_weekly.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Plot Reproduction:</p>
<pre class="r"><code># data preparation

expected_rentals_df_2 &lt;- bike %&gt;% 
  # use years 2015-2019 as reference
  filter(year %in% 2015:2019) %&gt;% 
  # calculate expected rentals (per day) per week over all years
  group_by(week) %&gt;% 
  summarise(expected_rentals = mean(bikes_hired))

excess_by_week &lt;- bike %&gt;% 
  # use years 2015-2019 as reference
  filter(year %in% 2015:2020) %&gt;% 
  # calculate actual rentals for each week for every year
  group_by(year, week) %&gt;% 
  summarise(actual_rentals = mean(bikes_hired)) %&gt;% 
  # join the expected rentals per week (over all years)
  left_join(expected_rentals_df_2, on = &quot;week&quot;) %&gt;% 
  # calculate excess_rentals, % change from weekly averages and helper variables for the ribbon and the rugs
  mutate(excess_rentals = actual_rentals - expected_rentals,
         perc_change = excess_rentals / expected_rentals,
         perc_chane_pos = ifelse(perc_change&gt;0, perc_change, 0),
         perc_chane_neg = ifelse(perc_change&lt;0, perc_change, 0),
         pos_neg = factor(ifelse(perc_change &gt; 0, 1, 0)))


# plot graph 2
ggplot(excess_by_week, aes(x = week)) +
  # add grey shaded rectangles
  geom_tile(aes(x = 19.5, width = 13, y = 0, height = Inf), alpha = 0.01, fill = &quot;gray78&quot;) +
  # add grey shaded rectangles
  geom_tile(aes(x = 46, width = 14, y = 0, height = Inf), alpha = 0.01, fill = &quot;gray78&quot;) +
  # add black line for percentage change
  geom_line(aes(y = perc_change), group = 1, color = &quot;black&quot;) +
  # add rugs at the bottom
  geom_rug(aes(color = pos_neg)) +
  # add red and green ribbons
  geom_ribbon(aes(ymin = 0, ymax = perc_chane_pos, group = 1), fill = &quot;green4&quot;, alpha = 0.2) +
  geom_ribbon(aes(ymin = perc_chane_neg, ymax = 0, group = 1), fill = &quot;red3&quot;, alpha = 0.2) +
  # faceting by year
  facet_wrap(~year) +
  theme_minimal() +
  # use specific breaks
  scale_y_continuous(labels = scales::percent, breaks = c(-0.6, -0.3, 0, 0.3, 0.6), minor_breaks = c(-0.45, -0.15, 0.15, 0.45)) +
  scale_x_continuous(breaks = c(13, 26, 39, 53), minor_breaks = c(0, 6.5, 19.5, 32.5, 45.5)) +
  scale_color_manual(values=c(&quot;red3&quot;, &quot;green4&quot;)) + # change colors of rugs
  theme(legend.position = &quot;none&quot;) + # without legend
  labs(y = &quot;&quot;,
       x = &quot;week&quot;,
       title = &quot;Weekly changes in TfL bike rentals&quot;,
       subtitle = &quot;% change from weekly averages \ncalculated between 2015-2019&quot;,
       caption = &quot;Source: TfL, London Data Store&quot;) +
  theme(axis.text = element_text(size = 12), # changes size of axis labels,
        axis.title = element_text(size = 15), # changes size of axis titles,
        strip.text = element_text(size = 13), # change size of facet titles
        panel.grid.minor = element_line(colour = &quot;gray90&quot;), # change color of minor grid
        panel.grid.major = element_line(colour = &quot;gray90&quot;), # change color of major grid
        plot.subtitle = element_text(size = 15), # change size of plot subtitle
        plot.caption = element_text(size = 12), # change size of plot caption
        plot.title = element_text(size = 18)) # change size of plot title</code></pre>
<p><img src="/blog/homework2_files/figure-html/weekly_changes-1.png" width="1440" style="display: block; margin: auto;" /></p>
</div>
<div id="details" class="section level1">
<h1>Details</h1>
<ul>
<li>Who did you collaborate with: Noor Alameri, Brigita Angkasa, Lujia Huang, Martino Armanini, Marco Laube, Deniz Oezdemir</li>
<li>Approximately how much time did you spend on this problem set: 12h</li>
<li>What, if anything, gave you the most trouble: The formatting in the two Challenges</li>
</ul>
</div>
<div id="rubric" class="section level1">
<h1>Rubric</h1>
<p>Check minus (1/5): Displays minimal effort. Doesn’t complete all components. Code is poorly written and not documented. Uses the same type of plot for each graph, or doesn’t use plots appropriate for the variables being analyzed.</p>
<p>Check (3/5): Solid effort. Hits all the elements. No clear mistakes. Easy to follow (both the code and the output).</p>
<p>Check plus (5/5): Finished all components of the assignment correctly and addressed both challenges. Code is well-documented (both self-documented and with additional comments as necessary). Used tidyverse, instead of base R. Graphs and tables are properly labelled. Analysis is clear and easy to follow, either because graphs are labeled clearly or you’ve written additional text to describe how you interpret the output.</p>
</div>
